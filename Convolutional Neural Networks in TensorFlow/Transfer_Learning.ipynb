{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergejhorvat/TensorFlow-in-Practice---Coursera/blob/master/Convolutional%20Neural%20Networks%20in%20TensorFlow/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "61424ab9-5c01-460e-d59c-a9758324f66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        }
      },
      "source": [
        "import os\n",
        "!pip install tensorflow-gpu==2.0.0\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "#pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# TF Version\n",
        "tf.__version__"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.17.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (41.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
            "--2019-11-10 22:34:49--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c13::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   240MB/s    in 0.3s    \n",
            "\n",
            "2019-11-10 22:34:50 (240 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c669d20-ffcf-48fc-d210-1772ac7df193"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_470 (Conv2D)             (None, 74, 74, 32)   864         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_470 (BatchN (None, 74, 74, 32)   96          conv2d_470[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 74, 74, 32)   0           batch_normalization_470[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_471 (Conv2D)             (None, 72, 72, 32)   9216        activation_470[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_471 (BatchN (None, 72, 72, 32)   96          conv2d_471[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_471 (Activation)     (None, 72, 72, 32)   0           batch_normalization_471[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_472 (Conv2D)             (None, 72, 72, 64)   18432       activation_471[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_472 (BatchN (None, 72, 72, 64)   192         conv2d_472[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_472 (Activation)     (None, 72, 72, 64)   0           batch_normalization_472[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 35, 35, 64)   0           activation_472[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_473 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_473 (BatchN (None, 35, 35, 80)   240         conv2d_473[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_473 (Activation)     (None, 35, 35, 80)   0           batch_normalization_473[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_474 (Conv2D)             (None, 33, 33, 192)  138240      activation_473[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_474 (BatchN (None, 33, 33, 192)  576         conv2d_474[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_474 (Activation)     (None, 33, 33, 192)  0           batch_normalization_474[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling2D) (None, 16, 16, 192)  0           activation_474[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_478 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, 16, 16, 64)   192         conv2d_478[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, 16, 16, 64)   0           batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_476 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_479 (Conv2D)             (None, 16, 16, 96)   55296       activation_478[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_476 (BatchN (None, 16, 16, 48)   144         conv2d_476[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, 16, 16, 96)   288         conv2d_479[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, 16, 16, 48)   0           batch_normalization_476[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, 16, 16, 96)   0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_45 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_475 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_477 (Conv2D)             (None, 16, 16, 64)   76800       activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_480 (Conv2D)             (None, 16, 16, 96)   82944       activation_479[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_481 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_45[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_475 (BatchN (None, 16, 16, 64)   192         conv2d_475[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, 16, 16, 64)   192         conv2d_477[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, 16, 16, 96)   288         conv2d_480[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, 16, 16, 32)   96          conv2d_481[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_475 (Activation)     (None, 16, 16, 64)   0           batch_normalization_475[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, 16, 16, 64)   0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, 16, 16, 96)   0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, 16, 16, 32)   0           batch_normalization_481[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_475[0][0]             \n",
            "                                                                 activation_477[0][0]             \n",
            "                                                                 activation_480[0][0]             \n",
            "                                                                 activation_481[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_485 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, 16, 16, 64)   192         conv2d_485[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, 16, 16, 64)   0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_483 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_486 (Conv2D)             (None, 16, 16, 96)   55296       activation_485[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, 16, 16, 48)   144         conv2d_483[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, 16, 16, 96)   288         conv2d_486[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, 16, 16, 48)   0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, 16, 16, 96)   0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_46 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_482 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_484 (Conv2D)             (None, 16, 16, 64)   76800       activation_483[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_487 (Conv2D)             (None, 16, 16, 96)   82944       activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_488 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_46[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, 16, 16, 64)   192         conv2d_482[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, 16, 16, 64)   192         conv2d_484[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, 16, 16, 96)   288         conv2d_487[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, 16, 16, 64)   192         conv2d_488[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, 16, 16, 64)   0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, 16, 16, 64)   0           batch_normalization_484[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, 16, 16, 96)   0           batch_normalization_487[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, 16, 16, 64)   0           batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_482[0][0]             \n",
            "                                                                 activation_484[0][0]             \n",
            "                                                                 activation_487[0][0]             \n",
            "                                                                 activation_488[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, 16, 16, 64)   192         conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 16, 16, 64)   0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 16, 16, 96)   55296       activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, 16, 16, 48)   144         conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, 16, 16, 96)   288         conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 16, 16, 48)   0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 16, 16, 96)   0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_47 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 16, 16, 64)   76800       activation_490[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, 16, 16, 96)   82944       activation_493[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, 16, 16, 64)   192         conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, 16, 16, 64)   192         conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, 16, 16, 96)   288         conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, 16, 16, 64)   192         conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 16, 16, 64)   0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 16, 16, 64)   0           batch_normalization_491[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 16, 16, 96)   0           batch_normalization_494[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 16, 16, 64)   0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_489[0][0]             \n",
            "                                                                 activation_491[0][0]             \n",
            "                                                                 activation_494[0][0]             \n",
            "                                                                 activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_497 (BatchN (None, 16, 16, 64)   192         conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, 16, 16, 64)   0           batch_normalization_497[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, 16, 16, 96)   55296       activation_497[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_498 (BatchN (None, 16, 16, 96)   288         conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, 16, 16, 96)   0           batch_normalization_498[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, 7, 7, 96)     82944       activation_498[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, 7, 7, 384)    1152        conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_499 (BatchN (None, 7, 7, 96)     288         conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 7, 7, 384)    0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, 7, 7, 96)     0           batch_normalization_499[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_496[0][0]             \n",
            "                                                                 activation_499[0][0]             \n",
            "                                                                 max_pooling2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_504 (BatchN (None, 7, 7, 128)    384         conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, 7, 7, 128)    0           batch_normalization_504[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, 7, 7, 128)    114688      activation_504[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_505 (BatchN (None, 7, 7, 128)    384         conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_505 (Activation)     (None, 7, 7, 128)    0           batch_normalization_505[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, 7, 7, 128)    114688      activation_505[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_501 (BatchN (None, 7, 7, 128)    384         conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_506 (BatchN (None, 7, 7, 128)    384         conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, 7, 7, 128)    0           batch_normalization_501[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, 7, 7, 128)    0           batch_normalization_506[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, 7, 7, 128)    114688      activation_501[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, 7, 7, 128)    114688      activation_506[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_502 (BatchN (None, 7, 7, 128)    384         conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_507 (BatchN (None, 7, 7, 128)    384         conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, 7, 7, 128)    0           batch_normalization_502[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_507 (Activation)     (None, 7, 7, 128)    0           batch_normalization_507[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_48 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, 7, 7, 192)    172032      activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, 7, 7, 192)    172032      activation_507[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_48[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_500 (BatchN (None, 7, 7, 192)    576         conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_503 (BatchN (None, 7, 7, 192)    576         conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_508 (BatchN (None, 7, 7, 192)    576         conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_509 (BatchN (None, 7, 7, 192)    576         conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, 7, 7, 192)    0           batch_normalization_500[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, 7, 7, 192)    0           batch_normalization_503[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_508 (Activation)     (None, 7, 7, 192)    0           batch_normalization_508[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_509 (Activation)     (None, 7, 7, 192)    0           batch_normalization_509[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_500[0][0]             \n",
            "                                                                 activation_503[0][0]             \n",
            "                                                                 activation_508[0][0]             \n",
            "                                                                 activation_509[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_514 (BatchN (None, 7, 7, 160)    480         conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_514 (Activation)     (None, 7, 7, 160)    0           batch_normalization_514[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 7, 7, 160)    179200      activation_514[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_515 (BatchN (None, 7, 7, 160)    480         conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_515 (Activation)     (None, 7, 7, 160)    0           batch_normalization_515[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 7, 7, 160)    179200      activation_515[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_511 (BatchN (None, 7, 7, 160)    480         conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_516 (BatchN (None, 7, 7, 160)    480         conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_511 (Activation)     (None, 7, 7, 160)    0           batch_normalization_511[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_516 (Activation)     (None, 7, 7, 160)    0           batch_normalization_516[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 7, 7, 160)    179200      activation_511[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 7, 7, 160)    179200      activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_512 (BatchN (None, 7, 7, 160)    480         conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_517 (BatchN (None, 7, 7, 160)    480         conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_512 (Activation)     (None, 7, 7, 160)    0           batch_normalization_512[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_517 (Activation)     (None, 7, 7, 160)    0           batch_normalization_517[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_49 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 7, 7, 192)    215040      activation_512[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 7, 7, 192)    215040      activation_517[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_49[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_510 (BatchN (None, 7, 7, 192)    576         conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_513 (BatchN (None, 7, 7, 192)    576         conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_518 (BatchN (None, 7, 7, 192)    576         conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_519 (BatchN (None, 7, 7, 192)    576         conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_510 (Activation)     (None, 7, 7, 192)    0           batch_normalization_510[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_513 (Activation)     (None, 7, 7, 192)    0           batch_normalization_513[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_518 (Activation)     (None, 7, 7, 192)    0           batch_normalization_518[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_519 (Activation)     (None, 7, 7, 192)    0           batch_normalization_519[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_510[0][0]             \n",
            "                                                                 activation_513[0][0]             \n",
            "                                                                 activation_518[0][0]             \n",
            "                                                                 activation_519[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, 7, 7, 160)    480         conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_524 (Activation)     (None, 7, 7, 160)    0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 7, 7, 160)    179200      activation_524[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, 7, 7, 160)    480         conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_525 (Activation)     (None, 7, 7, 160)    0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, 7, 7, 160)    179200      activation_525[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_521 (BatchN (None, 7, 7, 160)    480         conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, 7, 7, 160)    480         conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_521 (Activation)     (None, 7, 7, 160)    0           batch_normalization_521[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_526 (Activation)     (None, 7, 7, 160)    0           batch_normalization_526[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 7, 7, 160)    179200      activation_521[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, 7, 7, 160)    179200      activation_526[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_522 (BatchN (None, 7, 7, 160)    480         conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, 7, 7, 160)    480         conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_522 (Activation)     (None, 7, 7, 160)    0           batch_normalization_522[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_527 (Activation)     (None, 7, 7, 160)    0           batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_50 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 7, 7, 192)    215040      activation_522[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, 7, 7, 192)    215040      activation_527[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_529 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_50[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_520 (BatchN (None, 7, 7, 192)    576         conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, 7, 7, 192)    576         conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_528 (BatchN (None, 7, 7, 192)    576         conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_529 (BatchN (None, 7, 7, 192)    576         conv2d_529[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_520 (Activation)     (None, 7, 7, 192)    0           batch_normalization_520[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_523 (Activation)     (None, 7, 7, 192)    0           batch_normalization_523[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_528 (Activation)     (None, 7, 7, 192)    0           batch_normalization_528[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_529 (Activation)     (None, 7, 7, 192)    0           batch_normalization_529[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_520[0][0]             \n",
            "                                                                 activation_523[0][0]             \n",
            "                                                                 activation_528[0][0]             \n",
            "                                                                 activation_529[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_534 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_534 (BatchN (None, 7, 7, 192)    576         conv2d_534[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_534 (Activation)     (None, 7, 7, 192)    0           batch_normalization_534[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_535 (Conv2D)             (None, 7, 7, 192)    258048      activation_534[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_535 (BatchN (None, 7, 7, 192)    576         conv2d_535[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_535 (Activation)     (None, 7, 7, 192)    0           batch_normalization_535[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_531 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_536 (Conv2D)             (None, 7, 7, 192)    258048      activation_535[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_531 (BatchN (None, 7, 7, 192)    576         conv2d_531[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_536 (BatchN (None, 7, 7, 192)    576         conv2d_536[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_531 (Activation)     (None, 7, 7, 192)    0           batch_normalization_531[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_536 (Activation)     (None, 7, 7, 192)    0           batch_normalization_536[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_532 (Conv2D)             (None, 7, 7, 192)    258048      activation_531[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_537 (Conv2D)             (None, 7, 7, 192)    258048      activation_536[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_532 (BatchN (None, 7, 7, 192)    576         conv2d_532[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_537 (BatchN (None, 7, 7, 192)    576         conv2d_537[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_532 (Activation)     (None, 7, 7, 192)    0           batch_normalization_532[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_537 (Activation)     (None, 7, 7, 192)    0           batch_normalization_537[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_51 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_530 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_533 (Conv2D)             (None, 7, 7, 192)    258048      activation_532[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_538 (Conv2D)             (None, 7, 7, 192)    258048      activation_537[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_539 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_51[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_530 (BatchN (None, 7, 7, 192)    576         conv2d_530[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_533 (BatchN (None, 7, 7, 192)    576         conv2d_533[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_538 (BatchN (None, 7, 7, 192)    576         conv2d_538[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_539 (BatchN (None, 7, 7, 192)    576         conv2d_539[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_530 (Activation)     (None, 7, 7, 192)    0           batch_normalization_530[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_533 (Activation)     (None, 7, 7, 192)    0           batch_normalization_533[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_538 (Activation)     (None, 7, 7, 192)    0           batch_normalization_538[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_539 (Activation)     (None, 7, 7, 192)    0           batch_normalization_539[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_530[0][0]             \n",
            "                                                                 activation_533[0][0]             \n",
            "                                                                 activation_538[0][0]             \n",
            "                                                                 activation_539[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "9155867f-cdfc-441b-eec8-d19341333478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join( base_dir, 'train')\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-10 22:35:55--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c16::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  42.5MB/s    in 1.5s    \n",
            "\n",
            "2019-11-10 22:35:57 (42.5 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "4154dd24-0be9-47e4-c206-6e01f742af28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 20,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 1/20\n",
            "100/100 - 37s - loss: 0.4964 - acc: 0.7670 - val_loss: 0.2074 - val_acc: 0.9220\n",
            "Epoch 2/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.3764 - acc: 0.8335 - val_loss: 0.2450 - val_acc: 0.9340\n",
            "Epoch 3/20\n",
            "Epoch 1/20\n",
            "100/100 - 23s - loss: 0.3484 - acc: 0.8485 - val_loss: 0.1736 - val_acc: 0.9570\n",
            "Epoch 4/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.3340 - acc: 0.8530 - val_loss: 0.2814 - val_acc: 0.9440\n",
            "Epoch 5/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.3178 - acc: 0.8690 - val_loss: 0.4248 - val_acc: 0.9270\n",
            "Epoch 6/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.3115 - acc: 0.8695 - val_loss: 0.6179 - val_acc: 0.9210\n",
            "Epoch 7/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2950 - acc: 0.8750 - val_loss: 0.4913 - val_acc: 0.9290\n",
            "Epoch 8/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2967 - acc: 0.8770 - val_loss: 0.5804 - val_acc: 0.9260\n",
            "Epoch 9/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2799 - acc: 0.8845 - val_loss: 0.3282 - val_acc: 0.9480\n",
            "Epoch 10/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.3015 - acc: 0.8775 - val_loss: 0.3958 - val_acc: 0.9440\n",
            "Epoch 11/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2653 - acc: 0.8865 - val_loss: 0.3638 - val_acc: 0.9540\n",
            "Epoch 12/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2478 - acc: 0.8925 - val_loss: 0.4910 - val_acc: 0.9430\n",
            "Epoch 13/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2687 - acc: 0.8930 - val_loss: 0.2833 - val_acc: 0.9620\n",
            "Epoch 14/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2554 - acc: 0.9015 - val_loss: 0.3579 - val_acc: 0.9560\n",
            "Epoch 15/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2724 - acc: 0.8930 - val_loss: 0.4022 - val_acc: 0.9480\n",
            "Epoch 16/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2517 - acc: 0.8985 - val_loss: 0.3971 - val_acc: 0.9580\n",
            "Epoch 17/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2569 - acc: 0.8940 - val_loss: 0.3095 - val_acc: 0.9600\n",
            "Epoch 18/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2453 - acc: 0.9040 - val_loss: 0.5255 - val_acc: 0.9490\n",
            "Epoch 19/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2411 - acc: 0.9060 - val_loss: 0.3581 - val_acc: 0.9590\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "100/100 - 22s - loss: 0.2428 - acc: 0.9085 - val_loss: 0.3288 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "500369a8-2040-4146-c645-ccb6108d73f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPwISkFhInb+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2cPQAX9ddtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}