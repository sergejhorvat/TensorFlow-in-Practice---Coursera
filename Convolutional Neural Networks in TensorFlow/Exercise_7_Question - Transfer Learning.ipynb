{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergejhorvat/TensorFlow-in-Practice---Coursera/blob/master/Convolutional%20Neural%20Networks%20in%20TensorFlow/Exercise_7_Question%20-%20Transfer%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "7d2da591-333b-418b-81d5-b63a8d792115"
      },
      "source": [
        "# Import all the necessary files!\n",
        "!pip install tensorflow-gpu==2.0.0\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.17.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0) (41.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.7.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c05257b-efe7-4f8e-bdab-727be76177cf"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "# Your Code Here\n",
        "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-15 08:54:04--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  64.0MB/s    in 1.3s    \n",
            "\n",
            "2019-11-15 08:54:06 (64.0 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09d5cdde-1c43-42a4-a3ee-b7d814e0c138"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')# Your Code Here\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3hu55kWSlxp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05fcabae-b2e3-49c2-beb0-454ef2640da7"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(units=1024, activation='relu' )(x)# Your Code Here\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(rate=0.3)(x)   # Your Code Here               \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(units=1, activation='sigmoid')(x)    # Your Code Here       \n",
        "\n",
        "# Your Code Here\n",
        "model = Model(pre_trained_model.input , x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', # Your Code Here, \n",
        "              metrics = ['acc']) # Your Code Here)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "d76e7637-9911-4625-a4ac-1b0515626e4e"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-15 12:48:34--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 2a00:1450:400c:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "\r/tmp/horse-or-human   0%[                    ]       0  --.-KB/s               \r/tmp/horse-or-human  20%[===>                ]  29.31M   147MB/s               \r/tmp/horse-or-human  53%[=========>          ]  76.85M   192MB/s               \r/tmp/horse-or-human  85%[================>   ] 122.59M   204MB/s               \r/tmp/horse-or-human 100%[===================>] 142.65M   203MB/s    in 0.7s    \n",
            "\n",
            "2019-11-15 12:48:35 (203 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-11-15 12:48:37--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 2a00:1450:400c:c0a::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-11-15 12:48:37 (255 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "1b540ab3-9637-4730-c20c-8d865c20a467"
      },
      "source": [
        "# Your Code Here\n",
        "train_horses_dir = os.path.join('/tmp/training/horses')\n",
        "train_humans_dir = os.path.join('/tmp/training/humans')\n",
        "\n",
        "validation_horses_dir = os.path.join('/tmp/validation/horses')\n",
        "validation_humans_dir = os.path.join('/tmp/validation/humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print('total training horse images:', len(os.listdir(train_horses_dir)))\n",
        "print('total training human images:', len(os.listdir(train_humans_dir)))\n",
        "print('total validation horse images:', len(os.listdir(validation_horses_dir)))\n",
        "print('total validation human images:', len(os.listdir(validation_humans_dir)))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training horse images: 500\n",
            "total training human images: 527\n",
            "total validation horse images: 128\n",
            "total validation human images: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d2e0e2ff-b66b-4584-fe4f-6634b58b434f"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.,\n",
        "    zca_epsilon=1e-6,\n",
        "    zca_whitening = False,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest') \n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150,150)\n",
        "                                                    )    \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = train_datagen.flow_from_directory(validation_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150,150)\n",
        "                                                    )\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16a57d14-bc37-496c-b3c5-22247846f454"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            callbacks = [callbacks],\n",
        "            verbose = 2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 54s - loss: 0.2072 - acc: 0.9159 - val_loss: 0.1136 - val_acc: 0.9717\n",
            "Epoch 2/100\n",
            "100/100 - 54s - loss: 0.0748 - acc: 0.9696 - val_loss: 0.5468 - val_acc: 0.9170\n",
            "Epoch 3/100\n",
            "100/100 - 53s - loss: 0.0514 - acc: 0.9833 - val_loss: 0.1267 - val_acc: 0.9777\n",
            "Epoch 4/100\n",
            "100/100 - 53s - loss: 0.0445 - acc: 0.9839 - val_loss: 0.1891 - val_acc: 0.9676\n",
            "Epoch 5/100\n",
            "100/100 - 53s - loss: 0.0464 - acc: 0.9857 - val_loss: 0.5615 - val_acc: 0.9342\n",
            "Epoch 6/100\n",
            "100/100 - 53s - loss: 0.0298 - acc: 0.9919 - val_loss: 0.4730 - val_acc: 0.9393\n",
            "Epoch 7/100\n",
            "100/100 - 53s - loss: 0.0397 - acc: 0.9894 - val_loss: 0.9894 - val_acc: 0.8988\n",
            "Epoch 8/100\n",
            "100/100 - 52s - loss: 0.0373 - acc: 0.9904 - val_loss: 0.9107 - val_acc: 0.9049\n",
            "Epoch 9/100\n",
            "100/100 - 52s - loss: 0.0230 - acc: 0.9939 - val_loss: 0.6574 - val_acc: 0.9291\n",
            "Epoch 10/100\n",
            "100/100 - 52s - loss: 0.0138 - acc: 0.9940 - val_loss: 0.5226 - val_acc: 0.9352\n",
            "Epoch 11/100\n",
            "100/100 - 52s - loss: 0.0303 - acc: 0.9914 - val_loss: 0.9740 - val_acc: 0.9099\n",
            "Epoch 12/100\n",
            "100/100 - 52s - loss: 0.0199 - acc: 0.9939 - val_loss: 0.9015 - val_acc: 0.8947\n",
            "Epoch 13/100\n",
            "100/100 - 52s - loss: 0.0365 - acc: 0.9894 - val_loss: 0.7117 - val_acc: 0.9200\n",
            "Epoch 14/100\n",
            "100/100 - 53s - loss: 0.0378 - acc: 0.9889 - val_loss: 0.8492 - val_acc: 0.9140\n",
            "Epoch 15/100\n",
            "100/100 - 56s - loss: 0.0181 - acc: 0.9934 - val_loss: 0.7071 - val_acc: 0.9291\n",
            "Epoch 16/100\n",
            "100/100 - 57s - loss: 0.0148 - acc: 0.9959 - val_loss: 0.7341 - val_acc: 0.9271\n",
            "Epoch 17/100\n",
            "100/100 - 56s - loss: 0.0093 - acc: 0.9975 - val_loss: 0.5693 - val_acc: 0.9423\n",
            "Epoch 18/100\n",
            "100/100 - 55s - loss: 0.0268 - acc: 0.9939 - val_loss: 0.6510 - val_acc: 0.9302\n",
            "Epoch 19/100\n",
            "100/100 - 56s - loss: 0.0121 - acc: 0.9965 - val_loss: 0.6179 - val_acc: 0.9372\n",
            "Epoch 20/100\n",
            "100/100 - 57s - loss: 0.0333 - acc: 0.9934 - val_loss: 0.4805 - val_acc: 0.9494\n",
            "Epoch 21/100\n",
            "100/100 - 56s - loss: 0.0302 - acc: 0.9909 - val_loss: 0.5857 - val_acc: 0.9393\n",
            "Epoch 22/100\n",
            "100/100 - 55s - loss: 0.0100 - acc: 0.9975 - val_loss: 0.8853 - val_acc: 0.9200\n",
            "Epoch 23/100\n",
            "100/100 - 55s - loss: 0.0162 - acc: 0.9959 - val_loss: 0.8734 - val_acc: 0.9271\n",
            "Epoch 24/100\n",
            "100/100 - 53s - loss: 0.0050 - acc: 0.9985 - val_loss: 1.3655 - val_acc: 0.8755\n",
            "Epoch 25/100\n",
            "100/100 - 52s - loss: 0.0129 - acc: 0.9944 - val_loss: 0.7783 - val_acc: 0.9271\n",
            "Epoch 26/100\n",
            "100/100 - 53s - loss: 0.0126 - acc: 0.9949 - val_loss: 0.6956 - val_acc: 0.9332\n",
            "Epoch 27/100\n",
            "100/100 - 54s - loss: 0.0190 - acc: 0.9965 - val_loss: 0.7795 - val_acc: 0.9211\n",
            "Epoch 28/100\n",
            "100/100 - 54s - loss: 0.0081 - acc: 0.9980 - val_loss: 0.7428 - val_acc: 0.9281\n",
            "Epoch 29/100\n",
            "100/100 - 53s - loss: 0.0092 - acc: 0.9969 - val_loss: 0.8095 - val_acc: 0.9251\n",
            "Epoch 30/100\n",
            "100/100 - 56s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.3711 - val_acc: 0.9656\n",
            "Epoch 31/100\n",
            "100/100 - 54s - loss: 0.0332 - acc: 0.9939 - val_loss: 0.6055 - val_acc: 0.9372\n",
            "Epoch 32/100\n",
            "100/100 - 54s - loss: 0.0119 - acc: 0.9960 - val_loss: 0.3898 - val_acc: 0.9555\n",
            "Epoch 33/100\n",
            "100/100 - 54s - loss: 0.0045 - acc: 0.9980 - val_loss: 0.6676 - val_acc: 0.9393\n",
            "Epoch 34/100\n",
            "100/100 - 54s - loss: 0.0140 - acc: 0.9970 - val_loss: 0.6662 - val_acc: 0.9372\n",
            "Epoch 35/100\n",
            "100/100 - 53s - loss: 0.0099 - acc: 0.9965 - val_loss: 0.7700 - val_acc: 0.9312\n",
            "Epoch 36/100\n",
            "100/100 - 53s - loss: 0.0113 - acc: 0.9970 - val_loss: 0.7010 - val_acc: 0.9393\n",
            "Epoch 37/100\n",
            "100/100 - 53s - loss: 0.0224 - acc: 0.9970 - val_loss: 0.8009 - val_acc: 0.9271\n",
            "Epoch 38/100\n",
            "100/100 - 54s - loss: 0.0078 - acc: 0.9954 - val_loss: 0.9393 - val_acc: 0.9089\n",
            "Epoch 39/100\n",
            "100/100 - 54s - loss: 0.0217 - acc: 0.9959 - val_loss: 0.6455 - val_acc: 0.9383\n",
            "Epoch 40/100\n",
            "100/100 - 52s - loss: 0.0066 - acc: 0.9980 - val_loss: 0.6828 - val_acc: 0.9362\n",
            "Epoch 41/100\n",
            "100/100 - 55s - loss: 0.0227 - acc: 0.9954 - val_loss: 0.9855 - val_acc: 0.9150\n",
            "Epoch 42/100\n",
            "100/100 - 55s - loss: 0.0285 - acc: 0.9939 - val_loss: 0.4338 - val_acc: 0.9615\n",
            "Epoch 43/100\n",
            "100/100 - 55s - loss: 0.0033 - acc: 0.9990 - val_loss: 0.6471 - val_acc: 0.9423\n",
            "Epoch 44/100\n",
            "100/100 - 54s - loss: 0.0082 - acc: 0.9955 - val_loss: 0.6993 - val_acc: 0.9372\n",
            "Epoch 45/100\n",
            "100/100 - 54s - loss: 0.0203 - acc: 0.9959 - val_loss: 0.9171 - val_acc: 0.9231\n",
            "Epoch 46/100\n",
            "100/100 - 53s - loss: 0.0177 - acc: 0.9980 - val_loss: 0.9565 - val_acc: 0.9150\n",
            "Epoch 47/100\n",
            "100/100 - 53s - loss: 0.0101 - acc: 0.9970 - val_loss: 0.7818 - val_acc: 0.9342\n",
            "Epoch 48/100\n",
            "100/100 - 52s - loss: 0.0201 - acc: 0.9975 - val_loss: 1.0509 - val_acc: 0.9049\n",
            "Epoch 49/100\n",
            "100/100 - 54s - loss: 0.0162 - acc: 0.9965 - val_loss: 1.0195 - val_acc: 0.9211\n",
            "Epoch 50/100\n",
            "100/100 - 53s - loss: 0.0121 - acc: 0.9970 - val_loss: 0.9881 - val_acc: 0.9130\n",
            "Epoch 51/100\n",
            "100/100 - 52s - loss: 0.0080 - acc: 0.9985 - val_loss: 0.7258 - val_acc: 0.9342\n",
            "Epoch 52/100\n",
            "100/100 - 52s - loss: 0.0289 - acc: 0.9939 - val_loss: 0.5982 - val_acc: 0.9443\n",
            "Epoch 53/100\n",
            "100/100 - 51s - loss: 0.0179 - acc: 0.9959 - val_loss: 0.8939 - val_acc: 0.9130\n",
            "Epoch 54/100\n",
            "100/100 - 54s - loss: 0.0059 - acc: 0.9985 - val_loss: 0.8498 - val_acc: 0.9211\n",
            "Epoch 55/100\n",
            "100/100 - 54s - loss: 0.0110 - acc: 0.9970 - val_loss: 1.1104 - val_acc: 0.9018\n",
            "Epoch 56/100\n",
            "100/100 - 56s - loss: 0.0108 - acc: 0.9960 - val_loss: 1.0406 - val_acc: 0.9099\n",
            "Epoch 57/100\n",
            "100/100 - 55s - loss: 0.0117 - acc: 0.9964 - val_loss: 0.8244 - val_acc: 0.9190\n",
            "Epoch 58/100\n",
            "100/100 - 55s - loss: 0.0367 - acc: 0.9930 - val_loss: 0.9174 - val_acc: 0.9150\n",
            "Epoch 59/100\n",
            "100/100 - 55s - loss: 0.0182 - acc: 0.9959 - val_loss: 1.4070 - val_acc: 0.8806\n",
            "Epoch 60/100\n",
            "100/100 - 55s - loss: 0.0119 - acc: 0.9965 - val_loss: 1.4615 - val_acc: 0.8775\n",
            "Epoch 61/100\n",
            "100/100 - 53s - loss: 0.0162 - acc: 0.9954 - val_loss: 0.9413 - val_acc: 0.9231\n",
            "Epoch 62/100\n",
            "100/100 - 55s - loss: 0.0111 - acc: 0.9975 - val_loss: 1.0052 - val_acc: 0.9018\n",
            "Epoch 63/100\n",
            "100/100 - 56s - loss: 0.0029 - acc: 0.9985 - val_loss: 1.2396 - val_acc: 0.8927\n",
            "Epoch 64/100\n",
            "100/100 - 53s - loss: 0.0148 - acc: 0.9975 - val_loss: 0.9571 - val_acc: 0.9160\n",
            "Epoch 65/100\n",
            "100/100 - 55s - loss: 0.0029 - acc: 0.9985 - val_loss: 0.8216 - val_acc: 0.9332\n",
            "Epoch 66/100\n",
            "100/100 - 53s - loss: 0.0260 - acc: 0.9965 - val_loss: 1.1328 - val_acc: 0.9079\n",
            "Epoch 67/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 54s - loss: 7.2883e-04 - acc: 1.0000 - val_loss: 0.8147 - val_acc: 0.9302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "514fb2ec-191e-4173-e504-002a4843d0a6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd5hU1fnHP+/uUpVFekcUqdJdQRTE\nLthFbBFrLDGWxGgMllhILIkaNYklxtgCAf3ZC9g1YCz03sWli/Rd6rbz++Ods3N3dsqd3dmdwvk8\nzzwzc9uce+fe73nPe97zHjHG4HA4HI7MJSvZBXA4HA5HzeKE3uFwODIcJ/QOh8OR4TihdzgcjgzH\nCb3D4XBkOE7oHQ6HI8NxQr8fIiLZIrJTRDomcttkIiKHiUjCY4VF5CQRyfd8XyoiQ/1sW4Xfel5E\n7qzq/g5HJHKSXQBHbERkp+drQ2AfUBr4fp0xZnw8xzPGlAIHJnrb/QFjTLdEHEdErgZGG2OO8xz7\n6kQc2+EIxQl9GmCMKRfagMV4tTHm00jbi0iOMaakNsrmcMTC3Y/Jx7luMgAR+aOIvCoiE0SkEBgt\nIoNF5FsR2S4iG0TkryJSJ7B9jogYEekU+D4usH6yiBSKyDcicki82wbWjxCRZSKyQ0T+JiL/E5Er\nIpTbTxmvE5EVIrJNRP7q2TdbRB4XkS0ishIYHuX63CUiE0OWPSUifwl8vlpEFgfO5/uAtR3pWGtF\n5LjA54Yi8u9A2RYCR4Rse7eIrAwcd6GInBVY3hv4OzA04Bbb7Lm293n2/0Xg3LeIyNsi0sbPtYnn\nOtvyiMinIrJVRH4Ukds9v/P7wDUpEJEZItI2nJtMRL6y/3Pgek4J/M5W4G4R6SIiXwR+Y3PgujX2\n7H9w4Bw3BdY/KSL1A2Xu4dmujYjsFpFmkc7XEQZjjHul0QvIB04KWfZHoAg4E628GwBHAoPQVtuh\nwDLgxsD2OYABOgW+jwM2A3lAHeBVYFwVtm0JFAJnB9b9BigGrohwLn7K+A7QGOgEbLXnDtwILATa\nA82AKXo7h/2dQ4GdwAGeY/8E5AW+nxnYRoATgD1An8C6k4B8z7HWAscFPj8KfAk0AQ4GFoVsewHQ\nJvCf/CxQhlaBdVcDX4aUcxxwX+DzKYEy9gPqA08Dn/u5NnFe58bARuBXQD0gFxgYWHcHMBfoEjiH\nfkBT4LDQaw18Zf/nwLmVANcD2ej92BU4EagbuE/+BzzqOZ8Fget5QGD7YwLrngMe8PzOrcBbyX4O\n0+2V9AK4V5x/WGSh/zzGfrcB/xf4HE68n/VsexawoArbXgVM9awTYAMRhN5nGY/yrH8TuC3weQrq\nwrLrTgsVn5Bjfwv8LPB5BLA0yrbvAzcEPkcT+tXe/wL4pXfbMMddAJwe+BxL6F8GHvSsy0X7ZdrH\nujZxXudLgekRtvveljdkuR+hXxmjDKPs7wJDgR+B7DDbHQP8AEjg+xxgZKKfq0x/OddN5rDG+0VE\nuovIB4GmeAEwFmgeZf8fPZ93E70DNtK2bb3lMPpkro10EJ9l9PVbwKoo5QX4D3Bx4PPPAt9tOc4Q\nke8CboXtqDUd7VpZ2kQrg4hcISJzA+6H7UB3n8cFPb/y4xljCoBtQDvPNr7+sxjXuQMq6OGIti4W\nofdjaxF5TUTWBcrwUkgZ8o12/FfAGPM/tHUwRER6AR2BD6pYpv0WJ/SZQ2ho4T9QC/IwY0wucA9q\nYdckG1CLEwARESoKUyjVKeMGVCAsscI/XwNOEpF2qGvpP4EyNgBeBx5C3SoHAR/7LMePkcogIocC\nz6Dui2aB4y7xHDdWKOh61B1kj9cIdRGt81GuUKJd5zVA5wj7RVq3K1Cmhp5lrUO2CT2/P6HRYr0D\nZbgipAwHi0h2hHK8AoxGWx+vGWP2RdjOEQEn9JlLI2AHsCvQmXVdLfzm+8AAETlTRHJQv2+LGirj\na8CvRaRdoGPud9E2Nsb8iLoXXkLdNssDq+qhfuNNQKmInIH6kv2W4U4ROUh0nMGNnnUHomK3Ca3z\nrkEtestGoL23UzSECcDPRaSPiNRDK6KpxpiILaQoRLvO7wIdReRGEaknIrkiMjCw7nngjyLSWZR+\nItIUreB+RDv9s0XkWjyVUpQy7AJ2iEgH1H1k+QbYAjwo2sHdQESO8az/N+rq+Rkq+o44cUKfudwK\nXI52jv4D7TStUYwxG4ELgb+gD25nYDZqySW6jM8AnwHzgemoVR6L/6A+93K3jTFmO3AL8BbaoTkK\nrbD8cC/assgHJuMRIWPMPOBvwLTANt2A7zz7fgIsBzaKiNcFY/f/EHWxvBXYvyNwic9yhRLxOhtj\ndgAnA+ehlc8yYFhg9SPA2+h1LkA7RusHXHLXAHeiHfOHhZxbOO4FBqIVzrvAG54ylABnAD1Q6341\n+j/Y9fno/7zPGPN1nOfuINjB4XAknEBTfD0wyhgzNdnlcaQvIvIK2sF7X7LLko64AVOOhCIiw9EI\nlz1oeF4xatU6HFUi0N9xNtA72WVJV5zrxpFohgArUd/0qcC5rvPMUVVE5CE0lv9BY8zqZJcnXXGu\nG4fD4chwnEXvcDgcGU7K+eibN29uOnXqlOxiOBwOR1oxc+bMzcaYsOHMKSf0nTp1YsaMGckuhsPh\ncKQVIhJxdLhz3TgcDkeG44Te4XA4Mhwn9A6Hw5HhOKF3OByODMcJvcPhcGQ4MYVeRF4QkZ9EZEGE\n9RKYMmyFiMwTkQGedZeLyPLA6/JEFtzhcDgc/vBj0b9ElPk40dl6ugRe16JZBQmkM70XncJsIHCv\niDSpTmEdDofDET8xhd4YMwVN3xqJs4FXjPItcJDoJManAp8YY7YaY7ahaVmjVRgOh8Ox//J//wcT\nJtTIoRPho29HxWnD1gaWRVpeCRG5NjDD/IxNmzYloEgOh8ORRsyaBZdfDk8/DWVlCT98SnTGGmOe\nM8bkGWPyWrSINiGRIyMoKkp2CTKXzz6DoUMhPz/ZJQliTNX+89LS9LhX9uyJvU1JSeR1GzfCOedA\n8+bw+uuQlXhZTsQR11Fx3sz2gWWRljv2ZyZPhhYt4M47q3+sjRthxozoFlBBAcycGf+xCwthzpwa\nsa58UVYG06fH9/v79sF118FXX8HZZ8POnf73LSyExYtVlBOFMfDRR3DkkdC+Paxf73/fH3+EwYOh\nbVt47DF/YlqbbNqk1vfQodCwIfTpAw89VLGC3b0bXnsNzj0XDjhAt125suJx9u2D886DzZvhnXeg\nVauaKa8xJuYL6AQsiLDudHQaNQGOAqYFljcFfkAnNG4S+Nw01m8dccQRxlGDrF5tzHPPGbN3b+KP\nvW+fMc8/b8y6deHX/+MfxmRnG3PggcaAMR9/XLXf2brVmDvuMKZBAz1Ox476feHCYDneftuY8883\npn593WbcOP/H//RTY9q31/3atzfm1luNmTHDmLKyqpU3XlavNuaEE/T3zzvPmN27/e335z/rPmPG\nGJOVZcw55xhTWhp7v48/NqZdO933kEOM+d3vjJk5M3i+e/caM2+eMRMmGPPkk8YsWRL7mFOnGnPs\nsXrMTp30fzjvPH/nsWiRMQcfbEzDhsYMG6bHaNvWmGefNaaoyN8xaor33jNm+HC9j8GYww835re/\nNeboo/U7GDN4sDEXXRS8z9u0MebnPzemcWNd9q9/6bUtK9PlYMyrr1a7aMAME0nDI60o30AnKd6A\nzhS0Fvg58AvgF4H1AjwFfI/O65jn2fcqYEXgdWWs3zJO6GuOjRuN+dWvjKlbV//2K69MvHD9/e96\n7Pr19ebfvFmXl5UZc+edum74cC1Ljx76AGza5P/4u3YZ89BDxhx0kB7r4ouNeeEFY0aMCD54ffoY\n07Spfm7e3JgbbjDmqKOMadTImJUrYx//5pt1327djHn6aWPOPNOYOnV0WZcuxvzyl8Y884wK2bZt\nut+WLcZ8+aWe/3XXGXPuuRVfo0YZM368P9EdP14F4YADVAREVDh++in6fj/+qOd4xhn6/YkntMx3\n3RX9fG+6Sbfr3l1FfPhwY3JydNmhh+p1sNfW++rf35hHHtFKqaTEmKVLjXnjDWPuu8+YE0/UbVq3\nNuapp7TiffBBXfb229HP48sv9f9t1cqY6dN12RdfBIW0c2djHn3UmFWrYl/LRLJ9uzGXXRY0LMaM\n0crPyw8/GPPww3oPNmtmzNVXG/P553p9jNEyH3ecHuOcc4z5wx/08913J6SI1RL62n45oU8w27bp\nw37AAWrl/fznKvigYhCO2bONOeIIFVG/lJaqEPbtqw+EiArPffcZ87Of6e9de60xxcW6/Zw5Wumc\ndVbsCmffPhWM1q31OKefrvt7+fFHPZ+hQ/X3PvggaP3l56t4Dh4c/P1Qpk1TUQO9Pl4ressWY/75\nTxWw3NyKgmcrHe/3Xr2M6d07+OrQQdf17m3MO++EP98tW9QKBBW1FSt0+RtvaMXZubMxy5ZFvkZX\nX60CvXSpfvdaixMmxHe+mzfr+Z5+ulZUd9+tx5g3T6/l448bM3Bg8Jxtqwn0f+/SxZg//UkrEktR\nkQpg27YqmuEYP14r1R49VDS9lJUZ8/77FX938GD9z2fNMuatt9QIuPxyXf6nP0W+VvZ43srpvPPU\nOr/gAj2Wt8X73/9qCyMrS69FdVoVpaVaUVmD6+yz/RkAPnBCv78yY0ZQHC+8MNjkLi1ViyIrq7L7\n5KOPtHmZlaUP7X/+4++33ntPf8duv2CBMSNHBh/Khx6qLHCPP67rnn46/DFLSox5+WVt+oOK+NSp\n/s/fy4QJeox77qm4vLjYmPvvV6u1QwdjPvss+nHKytQye/99Padf/EIt28mTjVm7NryIl5bq73fp\nomUYNEgr0fvvV2u/e3f9/ZwcY/74x8qV0ddfa+ukWbPw5z9rlv5Xt9xScfm+fcYMGaJC/PDD2ro5\n/ni1lq1b6pNPYl+7SCxfruX9zW/0fKZPryjuoXz3nZbz+usrLt+9O2h8HHecuuZi/e4DD2jFEdrS\naNdOK1pQN2I49u7Vlo+3cjrsMGNOO02vM6hhcNVVWi4RrWi//jq+6xONefO0lVtQkLBDOqHfH3n/\nffVxHnywCn4ohYX6QDRpErQUX3xRxaZPH32Yhg1TAXrnndi/d8IJKhyh1s7Mmdp8DUdpqTGnnqpC\nZP3rBQX6QD39tFp2YMyAAcZ8+GH1XU2XX64V2JQp+v3774MugUsuCbpiaoriYrWUrf/fCsg556il\nGNpK8bJ8uYqRiLqs7H9WVqa+8ObNw5d/40b1u4O2Ro46SgXsL3+JLag1gRX0r77S77NmGdOzpy67\n6ab4+44WL9ZKdNo0Y3bs0GXFxcaccoq2Dr78suL2RUVqRYMxY8dWrpyKirTSvuwybZGCMddco89L\niuOEfn/jmWdU0AYMMGbDhsjbrVypVmKPHureAWNOOin4wBQUaFO5bt3olt+cObrvww/HX9YNG4xp\n0UL99QcfXNE6697dmNdfT1xfQkGBCmvHjlqRNGqklpvfVkui2LPHmLlzjdm5M779tm1TK7BhQ62A\nr7nGmL/9Ta/VM89E3m/v3sitjdqmsFCvf48eapXXqaP//UcfJfZ3tm3T+6dZs6AbrLhYO+hB+1Ni\nsXt3ZRdSCuOEPlnk56tl0bu3MV27qpC1bq3N6TVrIu/3+uvqD16/Pr7fKy3ViAnrx/ZjhXzxRbDz\n7bLLtLnvZcsWLX/DhkErLJQrrtD1VbUQP/5Y+wQuukgf/nfe0UooQb7LCnz3XfB8jz1W/6N0Y8MG\n7TS2ft5evSL3PaQiH3wQrMzPPz/YaZ9oli/XjvkePfTevOQS/c3HHquZ30syTuiTQWGhCmRurjbN\nL7xQhfTqq9WSbN/emPnzK+5TVqYdNfYhGDUqvt+0kS3XXx/fg//GG8b89a+RLb4ff1T/cqNGGnro\nZcMGFZxf/jK+siaTCRP0fG00RLqSn6/RTbNmJbsk8fPkk/o/1HQrwxoyLVros/HAAzX7e0nECX1t\nU1qqfsCsrPBN0jlzNPqgceOg/7qkRDvLrJXz+9/rZz/+cWP0Yc/OVuu6Jh6eNWvUcszJMeall4LL\n77lHy2mjPRyOVOOf/zRhO+IzDCf01aWsTCMs/vc/f9tby/rJJyNvs2qVNinr1tWIhTPP1H1uu00r\niqIibRG0axf0mUeiuFhdH61a1WwH2/btwRjp++9XX3OLFsHYbYcjVakp91AK4YS+ulifYp06Gu4X\njfHjTXlPfSzLeutWDRkEtf5DO4i+/VajLG64IfpxHnvMJGp0XUz27dPoFdCYeYgdkuhwOGocJ/TV\nZehQ9anbYel33RW+o/Crr4ypV0/DEkM7NSOxZ48O3580Kfz6m29WsY/Umli5UjtCzzij9qIqysqM\nufdeUz4SNRWiORyO/ZxoQi+6PnXIy8szM2bMSHYxgvzvfzBkCDzxBPzyl/p6/nk4/3x4+WVYuxbe\neEOzzs2cCYccAtOmaSa6RFBYCIcfDo0aaSrTevWC64yB4cPh669h0SLo0CHycWqCTz/VZFXdu9fu\n7zocjkqIyExjTF64dTm1XZi04+GHoVkzuPpqqFMHnnsOunWD229Xodu2TbcbOBD+/Ge47LLEiTyo\nwD/zDJxxBoweDWeeCb16QY8eWsF8/DH89a+1L/IAJ51U+7/pcDjixgl9NObPh/ffh/vv1zSjACJw\n223Qtata9MceCyNH1qzQnn46/PrXKvivv67LsrIgOxsGDdJWhsPhcETAuW6iMXo0vP02rF4NTZsm\nuzQ6ecGKFVoBzZ+vua1//3ttYTgcjv0a57qpCj/8ABMnwq9+lRoiD5CTo/7w7t21j8DhcDh8kBJT\nCaYkjz2m7pHf/CbZJXE4HI5q4YQ+HBs3wr/+pR2r7cLOZ+5wOBxpgxP6UHbsgJtu0rkcb7892aVx\nOByOauOE3mKMRrTYsMX779fIGofD4UhzXGcswKpVcMMN8MEH0L8/vPceHHFEskvlcDgcCWH/E3pj\nYN06Hb1qX998ox2vjz0GN9+s0S0Oh8ORIex/inbmmWq5g4507dcPrrkGbr0VDj44uWVzOByOGmD/\nEvqdO2HyZBg1Ske39utXMXeMw+FwZCD7l9DPmgVlZXDFFZo6wOFwOPYDfEXdiMhwEVkqIitEZEyY\n9QeLyGciMk9EvhSR9p51fxaRhSKyWET+KiKSyBOIi2nT9H3gwKQVweFwOGqbmEIvItnAU8AIoCdw\nsYj0DNnsUeAVY0wfYCzwUGDfo4FjgD5AL+BIYFjCSh8v332naYRbtEhaERwOh6O28WPRDwRWGGNW\nGmOKgInA2SHb9AQ+D3z+wrPeAPWBukA9oA6wsbqFrjLTpjlr3uFw7Hf4Efp2wBrP97WBZV7mAiMD\nn88FGolIM2PMN6jwbwi8PjLGLA79ARG5VkRmiMiMTZs2xXsO/vjxR81C6YTe4XDsZyRqZOxtwDAR\nmY26ZtYBpSJyGNADaI9WDieIyNDQnY0xzxlj8owxeS1qyq1i/fOuE9bhcOxn+BH6dYB3Vo32gWXl\nGGPWG2NGGmP6A3cFlm1HrftvjTE7jTE7gcnA4ISUPF6mTYPsbPb26E9RUVJK4HA4HEnBj9BPB7qI\nyCEiUhe4CHjXu4GINBcRe6w7gBcCn1ejln6OiNRBrf1Krpta4bvvoHdvjj+9ITffnJQSOBwOR1KI\nKfTGmBLgRuAjVKRfM8YsFJGxInJWYLPjgKUisgxoBTwQWP468D0wH/XjzzXGvJfYU/BBWRlMnw6D\nBvHDD5q7rLS01kvhcDgcScHXgCljzCRgUsiyezyfX0dFPXS/UuC6apax+ixfrumHBw5k5zjYtQtm\nzHDueofDsX+wf6Qp/u47AMryBrJrly6aNCnK9g6Hw5FB7B9CP20aHHgguzr2KF80eXISy+NwOBy1\nyP4j9Hl57NyTDUD79uqy/+mnJJfL4XA4aoHMF/q9e2HOHPXP79RF55+v7x99lLxiORwOR22R+UI/\ndy4UF8OgQeVCP3QotGzp/PQOh2P/IPOF3pOxsrBQP+bmwogR8PHHLszS4XBkPhkj9AUFcO+95QE2\nQb77Dtq0gXbtyi36Aw9Uod+6NVgPOBwOR6aSMUJfXAxjx8K334asmDZNA+ZFyoW+USM45RSdJta5\nbxwOR6aTMULfqJG+FxR4Fm7dqoOlAhkrvRZ9kyYweLALs3Q4HJlPxgh93bpQvz7lfnhAYyihXOjt\nugMP1PfTToOZMzWDscPhcGQqGSP0oFZ9BYt+7lx9P+IIoKJFD+qnBxdm6XA4MpuMEvrc3BCLfts2\nqFMHGjcGVOjr1tUXQL9+2k/r/PQOhyOTyTihr2DRFxTowsB85Dt3Bq150MXDh2uYZUlJ7ZbV4XA4\naouMEvpKrhsr9AEKCysKPaj7Zvt2mDWrdsrocDgctU1GCX0l101hYTAch8oWPUC3bvq+enXNl8/h\ncDiSQUYJfSyLfufOCroPaCoEcAnOHA5H5pJRQl/Jog8j9KEWffPm6qt3Qp+ZLFkCJ58cjLhyOPZH\nMk7o4/XR5+RAs2ZO6DOVqVPh009hwYJkl8ThSB4ZJfSNGmlW4uLiwAIfFj2o+2bjxtopo6N22bpV\n39evT245HI5kklFCbzW93H3jw0cPKvTOos9MtmzRdyf0jv2ZjBL6CvluSkpgzx7fFr0T+szEWfQO\nR4YJfQWL3pr1AfUvLYXdu8MLfatWTugzFSv069YltxwORzLJSKEvKCDYKxtYuGuXfo1k0W/fDvv2\n1XwZHbVLprtuPv88eI4ORyR8Cb2IDBeRpSKyQkTGhFl/sIh8JiLzRORLEWnvWddRRD4WkcUiskhE\nOiWu+BWp4LoJEfrQhGZebCz9pk01VTJHsshk101REZx6Kjz+eLJL4kh1Ygq9iGQDTwEjgJ7AxSLS\nM2SzR4FXjDF9gLHAQ551rwCPGGN6AAOBGnOSVHDdRBD6SJ2x4Nw3mUgmW/Tbt2tX1KJFyS6JI9Xx\nY9EPBFYYY1YaY4qAicDZIdv0BD4PfP7Crg9UCDnGmE8AjDE7jTG7E1LyMFTVom/VSt9diGVmYYxa\n9NnZKoq7a+zOSw7bt+v70qXJLYcj9fEj9O2ANZ7vawPLvMwFRgY+nws0EpFmQFdgu4i8KSKzReSR\nQAuhAiJyrYjMEJEZm6rhP4lm0YdOOuLFWfSZyZ492u9i8xllmlVvhX7FCjfJvSM6ieqMvQ0YJiKz\ngWHAOqAUyAGGBtYfCRwKXBG6szHmOWNMnjEmr0WLFlUuRAWL3ip7HD56J/SZhXXb9O6t75kq9EVF\nsGpVcsviSG38CP06oIPne/vAsnKMMeuNMSONMf2BuwLLtqPW/5yA26cEeBsYkJCShyE7Gxo2DHHd\nBNQ/mo/+wAN1GkIn9JmF7Yjt1UvfM1XowblvHNHxI/TTgS4icoiI1AUuAt71biAizUXEHusO4AXP\nvgeJiDXTTwBqtOuoPLGZFfqACR/NohdRP73z0WcWVuitRZ9psfReoV+2LHnlcKQ+MYU+YInfCHwE\nLAZeM8YsFJGxInJWYLPjgKUisgxoBTwQ2LcUddt8JiLzAQH+mfCz8FCeqrigQFU9W7sEovnowY2O\nzUSs6+aQQ7Sll6kWfYMGzqJ3RCfHz0bGmEnApJBl93g+vw68HmHfT4A+1ShjXFSw6EPSH0B0oc80\nIdjfsRZ9s2bQtm3m/b/bt2v21d69ndA7opNRI2PBk6o4jNDXq6dzhYfDWfSZh7XomzaNLvR798KF\nF2ru+nRi+3Y46CCNKnKuG0c0Mk7oK7hufCQ0s9h8N8bUfBkdtcPWrerWaNAA2rWL7KOfPRteew1e\nD9smTV2s0HftCmvXBtN8OByhZJzQl7tuCgvjEvqWLTWPvbeDy5HebN2q1jwELfpwFfnixfo+b17t\nlS0ReC16cFa9IzIZJ/QVLHpPLGW42aW8uFj6zGPLlopCv2cP7NhReTsr9PPn117ZEoETeodfMk7o\no3XGhouht9g0CE7oM4etW7UjFlToIbyf3gr9smVaGaQLVui7dNHvrkPWEYmMFPqiIti3Y2/crhtw\nsfSZhNd10y6QtCOc0C9ZovdGWVl6JQizQt+gAXTs6ITeEZmME/oKaRCqIPTOos8ctmypbNGHdsju\n3Qs//ABnBUaEpJOf3go9uMgbR3QyTujLE5uZAyoIfSwfffPmOkLWCX1mYDNXWou+TRt9D7Xoly1T\nS/7003VQVboI/b596mbyCv3SpS5qzBGejBP6coue3Lh89Dk5av05101msHu3uvCs0DdsqKIYKvTW\nP3/44TrwKF2E3nYqW6Hv2lWNGXf/OsKRcUJfPp1gGKGPZtGDGzQVjbKyYPqgdMAOlrKuGwg/aGrx\nYm3Jde0KffrA3LnpYRXbMGCvRQ/OT+8IT8YKfSGNKkwMvmePE/rq8Oyz2uEXLjwxFbHpD6xFD+EH\nTS1ZAp06aYdm795aQfz4Y60Vs8o4oXfEQ8YJfTjXTaw8NxYn9JGZNElF/tNPk10Sf3jTH1giWfQ9\neujnPoGMTOngvgkV+g4dNNW265B1hCPjhL6CRe9jvlgvLlVxeMrK4H//08+TJkXfNlXwJjSztG0L\nGzbo+YC29JYuDQq9TWecjkKflaXx9M6id4QjY4W+qhb9jh0a0eAIsmCBCsuBB8Lkyenhww7numnb\nVifT3rxZv+fn639thb5pU2jfPj2EPrQzFoKRNw5HKBkn9AccoO9VFXqAakxbm5FMnarvt96qFvHc\nucktjx/CuW7soCnrp7cRN1boQd036SD0oRY9aIfyypWas8nh8JJxQp+VBY3q7QvruvEr9M5PX5Ep\nU9TS/cUv9Pvkycktjx+2btWQyvr1g8tC0yBYoe/ePbhNnz66vKiodspZVWwu+oYNg8u6dVN31MqV\nySuXIzXJOKEHaFRnLwVZB2kCeoKzS/nx0YPz03sxRi36oUOhdWsYMCA9/PTewVKWUKFfskQrd+92\nffqoRZzqLhA7KlYkuMxF3jgikZFCn5uzh8KcJuXfnUVfdVauVHfN0KH6fcQI+OYb2LYtueWKhTf9\ngaV1axVGr0XvddtA+kTeeNMfWLp21fd0iLwpKgp2ijtqnswU+uxdFGQ7oU8E1j9vhf6009Q98Mkn\nySuTH8JZ9HXq6H+8bp22VEJHmX0AACAASURBVMIJfdeuULdu6qcsDif0TZpAixapb9Eboy3De+6J\nva0jMWSk0DeSnRRI8CnwK/QHHqg+Xee6CTJ1qgpmz576fdAgFZRU99N7c9F7sbH0GzeqWIYKfZ06\nuiwdLXpIj8ibBQtg4cLUr0wziYwU+lx2aGdsAOujjyX0IsEpBR3KlCkwZIh2cgNkZ8Opp6rQp3LT\n25uL3osV+nAdsZZ0iLzZvh0aN668PB2yWFojwRlUtUdGCn2jsgIKTFDVd+5USz0nJ/a+mT46dtky\nGDjQ3zD/H3+EFSuCbhvLiBH6kM6ZUzNlrC6hmSu9hAp9qEUPKvTr1gVDNFORSBZ9167632zYUPtl\n8ovtzE+HVBOZgi+hF5HhIrJURFaIyJgw6w8Wkc9EZJ6IfCki7UPW54rIWhH5e6IKHo3c0m0Ulgbj\nzvwkNLNkutB/8AFMn+4vcibUP2859VR9T9Xom507NXImnNC3a6f/7/z5ek+0b195G9shm8quhUhC\nf/bZ2uq6//7aL5MfCgp0lHVOjgp9Ogy+ywRiCr2IZANPASOAnsDFItIzZLNHgVeMMX2AscBDIev/\nAEypfnH9kVuyhYLiBuU3UbxCn8lNytmz9d2KeDSmTtU47QEDKi5v1Qry8lLXTx8u/YGlbVsVly+/\nVLeNNzzRkuqRN0VFmoY5ko/+hhvgn/9MzfJ/+qmOTj79dB2VnC5J8tIdPxb9QGCFMWalMaYImAic\nHbJNT+DzwOcvvOtF5AigFfBx9Yvrj0b7tlBqssvn/ywsjB1Db7E++ky1NOIV+sGDtYMylBEj4Ntv\ng6KaSoRLf2CxsfRLloR324DeAy1apKZQQvj0B17uvVfX/frXqXcfT5qk4xjPPVe/Z7JRlUr4Efp2\nwBrP97WBZV7mAiMDn88FGolIMxHJAh4DbqtuQX1TXExuiTpXbSdsvBZ9SUlwiLmlpCSBZUwSe/ao\nb7pJE/j+++h+3O3bNdVBqNvGctpp2hn7ca1V3/4Jl4veYoUewnfEglr5Ve2QLSur+U7qcOkPvDRt\nCmPHwhdfwDvv1GxZ4sEYbQWeckrQZeb89LVDojpjbwOGichsYBiwDigFfglMMsasjbaziFwrIjNE\nZMam6iaaKSykEarwdqKMeIUeKvrpN2xQgXj55eoVLdksXKgx8Ndco9+jWfVff60PZiShP/JIFZRU\nFPpoFn07j4kSyaIH6NdPO5tffjk+q/iaa+Dkk/1vXxViCT3AdddpSOxtt6VOkr5587QjfMQIHbwG\nTuhrCz9Cvw7o4PnePrCsHGPMemPMSGNMf+CuwLLtwGDgRhHJR/34l4nIw6E/YIx5zhiTZ4zJa9Gi\nRdXOxFJQQC6q8FWx6MOlQbjrLk10tmhR9YqWbKzb5qqrNPnblCi9JlOnaofZUUeFX5+drWKYitck\nXEIzS/PmweiraEJ/2206ZuCKK+D88/1F4OzYAePHq/8/3tm4vv0WZszwt60foc/Jgccf15bbk0/G\nV5aawvbpDB8eFHrnuqkd/Aj9dKCLiBwiInWBi4B3vRuISPOAmwbgDuAFAGPMJcaYjsaYTqjV/4ox\nplLUTkIpLCwX+kRY9DNnwksv6edU9EfHw+zZ6h/t0kV979Es+qlTtcPVmzQrlFSdkDqaRZ+VpROF\n5+RA586Rj9G6tQr2ww/Du+9qrvoPP4z+u2+8odZzWZm2iOJh9GgNe73jjtgJ1fwIPaiL5Iwz4I9/\nTA1BnTRJjYO2bdV9aCNvHDVPTKE3xpQANwIfAYuB14wxC0VkrIicFdjsOGCpiCxDO14fqKHyxqag\noJLrJp7OWK/QGwO/+pV2zHXqlNpx1X6YPVsftKwsdcnMn1+5LwJg1y4NwYzktrF07ar7p1pa561b\ntcUSyGlXibZttbIL18nsJTsbfvc7+O47FaYRI+Bvf4u8/bhxep/k5Pjr7LYYA2vWaAX08MMq+AsX\nRt7er9ADPPYY7N2rPvtksn27Vn6nnabfs7K09eyEvnbw5aM3xkwyxnQ1xnQ2xjwQWHaPMebdwOfX\njTFdAttcbYyp5BU0xrxkjLkxscUPQzVdN82ba2fcTz/Ba69pzO8DD+h8qels0ZeWqo+0f3/9PnSo\nCoydOcrLhAlqVZ51VuV1Xmy2xFQbiRkp/YHlnnvgodAA4Cj0768tu5NO0ogWe195WbtWWwBXXKHh\nqPEI/bZter1vu007T9evhyOOUNdLuNZSPELftauGMia7L+XTT/UeHDEiuKx169RoaewPZN7I2BCL\nvqRELRq/Qp+To9Ea+flw++1qAV95pQpHOgv9smUae22FftAgtWhDBckYeOYZ6NULjjkm+jFTNS1u\npPQHltNO04FF8VC/vrpAtm2Df/yj8voJE/TaXXKJVqLTpul95wcb/dS2rVauCxZoh+5vfhO+wti+\nXVsbdpKdWAwcqCOck5lxdNIkrZi8fT7Ooq89MlLovRb9rl262K/Qg7pvxo+H1avhiSf0oWraNDGu\nm6++it78rylsR6wV+oYN1Qcf2iE7fTrMmgXXXx9+MJGXgw/WTI+pKPTRLPqqMmgQnHhi0B3iZdw4\nFbHDDlOh37dPr6UfbNrkNm30vWVLePZZ/bxgQeXtw+Wij0Zenr7PnOlv+0TjDav0piFp3doJfW2R\nkULfkN1kZRkKCvxPOuLFxtKfdx4MG6bLmjWrvkVfWgo//7k20Ws7Idjs2eqz9kaaDB2qkR52YBmo\nNX/AAdo5GIvsbBW2VHTdRLPoq8Ndd6k4vfhicNm8efqy12zIEH33676xFr0Vevu5fn2NmgklUvqD\nSFih9xvVk2jmzNFr5nXbQNB1k8rJ8TKFzBP6wkIEFfaCAv8pir20aaOi+MgjwWVNm6oV5xXFeHnz\nTRXFoqLa78CcPVvdMd4OyKFDNSfMd9/p961bYeJEFSw7yXosUjEtbk1Z9ADHHaeW+5//HJybdfx4\ntVQvuEC/N2sGhx9ePaHPyoJDD02M0DdpohFGflsYoFZ4//7w1FP+94mEnbtg+PCKy1u1UuMnnV2i\n6ULmCX1BATRqRG6uUFhYNaEfO1Y7rw45JLjMWohVdd8Yo526Nt3vmjXRt08kxqjQW7eN5ZhjtPlv\nBenll7Uyu/56/8fu1k3FKNEjh2fOrFqMfrTMlYlABO68U/twJkxQa/Q//9FEb94hIEOHakd3aWns\nY65fr4ZJ6D3auXNihB50gFs8Fv3mzWqJWyOgOixerJWYjZ237E+DpqZODbrokkFmCn1ubrUs+sMO\ng2OPrbjMCkdVrY/JkzWlwA036PfaFPo1a7TcoULfpInGh0+ZogL57LMaX9+3r/9jd+2qlm1+fuLK\nu3On+nPtCN54KCzUSqemXDegsel9+mjkzpdfasRNqKtr6FAty9y5sY+3YUNFa97SubNO5RgaeVMV\noc/L0z4nv5lZbSstEemOv/8+/JiF/UXoS0rUEIgn0ivRZKbQN2pEbq4+aFXx0YfDCn1VLHprzXfs\nCGMCw8VWr65eeeIhtCPWy9ChOgfsxx+rWykeax5qJvLmuee0Ypo+XSOF4iHaYKlEIaIDm5YsgWuv\nVSMiNBTVjkHw476xKTZC6dxZzz9UCKtq0YN/q972u9Sk0IcbhZ6JrFihLt9EGkPxkplCn5tLbm7V\nLfpwWAuxKhb9lCk6WOT224OdbLVp0c+eHUzUFcrQoRqZdPPNeo7nnx/fsRMt9Pv2waOPamvD23/g\nl2jpDxLJ+edry+/777XTPnQEcYcOOnjKj9CvXx/ZoofK7puqCH3//noP+PXT2/+zuu6GPXv0GPuz\nRW8Hv9WmcRdKxgp9dVw34aiO6+bBB9V6ueoqfdg6dKh9i75bt/Bx19byXLZMxwvUrx/fsZs102uT\nqMibl15SK/K55yr2H/glWi76RJKdrb56gMsuC7/N0KFa/mgpIoyJ7rqBikIfLRd9NBo10ogrvxa9\nFfpt2/yPBwjHypX6Hk7oc3P1fttfhL42jbtQMlboresm0UIfr+tm+nR1i/zmN9CggS7r0KF2//Q5\nc8K7bUBdBvYhvO66qh0/UZE3JSXwpz/pAJ/zztP+g6oKfU1b9KCjYOfNgxNOCL9+6FD1iUerBAsK\n1OoN57rp1Ek7771CHysXfTTy8vR+9JObyFvm6gixLXs4oRfZP2LprdBv2xbUo3D85S/q4q0JMk/o\nCwsrWPR+JwaPRcOGan3Ea9E/9JA+lL/4RXBZx461J/RbtmjrIZLQg5btxhvVFVEVEiX0EyfCDz9o\nrLpIsP8gnoie2nLdgJaxd+/I6/346UMHS3mpW1eNAq/Qx5P+IJQjj1R/+Lp10bcrKVG/su2Ur477\nJprQg7Z0M91Hv2CBtgAh+nP/+uvw+eeR11eHzBP6EIu+sFAtaXuhq0O8aRBWrYK33oKbbqoYl96h\ngz48Ng47Ubz0kj5QH3wQXGYn8I4m9LfdVr3Rul27qvshXA4Yv5SVaaXYq5dGtUCw/8B2JvuhNi36\nWHTrpiGX0YQ+XAy9l9AQy+pa9BDbT5+fr/emHSxYnQ7Z77/Xez+SKy3TLfqiIm0dDR6s36MJ/cqV\nFUO6E0lmCb0xFYTeGLUWqmvNW5o1i891Y5tsoSMCO3TQsiU6rvadd/RmOeMMtdK9IhlN6KtLIpKb\nvfOOxs3feWdwrIG1iCPlzd+0SS1+L1u36v9dt27Vy5IobKvEj9CHc91AZaGvjkXft68O7Irlp7f/\n43HHVSxjVbARN5HSNWS60C9fri0kqwGR+uZ271atOvTQmilHZgn97t1qGjZqVB5OuX594oQ+Xove\n/qkHH1xxeceO+p5o983s2XDOOfDb32pnZr9+Ohq3Q4ea7ZysbuSNMdph3blzxagf238QSSivvhqO\nPrrizF81mf6gKgwdqu6otRHmWIvmugE9/82bgym3qyP0DRpoiymWRW//x2OO0Yqhuq6baHn/W7XS\n88uEqTrDYY29k0/Wyi7SM29DL51F7wf7NAQselBrpLox9JZ4E5utWqUpB0JHBHYIzNeVyMibrVv1\n9+zw/C++0GbjN9/UrDUPQYstnEU/fjz8/vfR9//yS7Uyf/e7ikmvQIXyq68q50NZvRref1/dAldd\npSmloWZHxVaFWH76DRu0/yfSPRoaeVMdoYfgCNloHbJLl+o1bNlShbiqFn1pqQpYrAlejEm9OQ0S\nxYIF2kLt3Vsr80hCb6OTnND7IYzQJ9Kijzex2apVKupZIVfZCn0iLfpQX/ywYRoR8rvfwS23JO53\nwlG/vkaIhFr0xcXaunj++ej729Gj551Xed3QoVq5LllScflzz6lAfPutWvWXXKLCHysXfW3Tt69W\n9pFGyNrBUpFcG4kW+rw8jf6wwhKOZcu03wW0bFUV+jVr9B6IJfSQue6bhQs1yKF+fW3JRzLufvhB\n353rxg8eobcW0vbtiXfd+J06b/XqoJvGS6NG+qAm0qIP54tv3FhnLLK+1pokXOTNu++qSNgOxEjY\n9Y0bV15nU1F4LeKiIq08Tj9dY8M/+EDPe9QofbBSyXWTk6OzWS1eHH59pMFSlnBCH08u+lD8jJBd\nujTojmvTpuqum1gRN5D5o2MXLtQEdxA9rHrlSm3ZVXfK7EhkltDbsA+PRQ+JFfp9+/wPy1+1qrJ/\n3pLoWPrZs6Fdu5q7UWLRtatagt5K8Jln9H3PnugRRgUFKlzhIqM6d1arz9sh+/bbKgw2XUNurs7n\n2rWrHiuVLHrQyiiS0EcaLGXJzdVZz7xCH08u+lB69dLMrJH89IWFKuxeoa+qRe9H6DPZot+7V8NU\nQ4U+nKH4ww9qzVf1f41FZgl9GIseEuejjycNQnGxPjDhLHpIfCx9uOyUtUm3bhrlY62/Zcvgs8+0\n8oHooZcFBeGteQgfufLMM+oqOvXU4LKmTTUd7pAhlRPSJZsePdRi21dpgs3IeW68eCNvtm+PfK38\nUKeOdtJHsuiXL9d3r+tm8+bYE5aH4/vv9ffat4+8jbXoM1Holy7Vfgor9B07qtETrp/vhx9qzj8P\nGSz0NWXRgz+hX7dOOxCjWfSJct3s3q0+7GQLPQTdN88+q26LGwOzBEdz3+zYET3//dChWimuWqWW\n8Zdf6ije0BZAq1ZaIVx8cZVPo0bo0UMf+BUrKi63I7ejWfRQWeir6p+35OVpGuhwKZTt/+e16KFq\nQvz99ype0cawHHCAPp+ZKPQ24qZXL32P1DdnTM3G0EOmCn0ge6UlkZ2x4C/yZtUqfY8k9HaycTvV\nYXWYP18rlWQKvbUAly1Tq+Wll2DkyOBy+9eEIzD0ISJeP/2zz6qVeNVVCSl2rdC9u76Hum9iDZay\ndO6s4lBUlBihP/JIrWDCRUktXaqtKDtK2patKu6bWKGVllSdJHzfPk1GWFUWLlRjxz4DkaLttmzR\n/6OmOmIhU4U+N5d69YKhesmw6O2fGcl1k8jIm9oYFBWLdu20M2npUnj1VY3suP76oIDHsuijuSN6\n9dL1H36oMfOjRmnoX7pgreNIQu/HdVNWpsZDIoTeTtAdbrj9smVqnNjkdrZs8Qq9MfEJfSpa9K++\nqmMJrNEWLwsXake8HbwXafyMjbhxFr1fCgr0qtarh0hQZBIZRw/xWfRW0ENJpNDPmaMPf6TWQ22Q\nlaWWy9Kl6kPv0UNDPK2AV8eiz87WB+4//9FKId6c+cnmgAP0vwkV+liDpSzeyJtECH23bhrXPX58\n5XXeiBtv2eKNvNm8WV1TfoS+VavUFHpbuVV1IKA34gY0UKJu3crPvA11TbpFLyLDRWSpiKwQkTFh\n1h8sIp+JyDwR+VJE2geW9xORb0RkYWDdhYk+gQoEEppZrMAnw6JftUqtTpuxMpREjo6dPVs72Gqq\nx94vXbvCf/8L06ZpCgZvZRtL6GN1MA4dqlbi4YcHJ99OJ3r0qDwWIB7XDSRO6EFnxPrmm4rpFYxR\ni94r9C1baiUeyaLfty/8PMp+Im4skVw3RUXVm6O5utgxC+Gmc4zF7t26n1fos7LC981Zi75TpyoV\n0xcxhV5EsoGngBFAT+BiEekZstmjwCvGmD7AWMBOmrUbuMwYczgwHHhCRBJwm0YgxDS0HxMl9A0a\n6Muv6yaahd2unQphdTtkS0p0YFQy3TaWbt30Bm/QIJij3Qp4dTpjAY4/Xt9/+cvkV2hVwQq9d4Tv\nhg0a6hhLuFu3DrrFdu1KjNBffLFex//8p2J5du4M+pRBW1PRRseOHl05lxPEL/TbtlWOSrrySk0d\nkCyqI/RLlmjFaTtiLeHCqleuVGs/UToVDj8W/UBghTFmpTGmCJgInB2yTU/Aevy+sOuNMcuMMcsD\nn9cDPwE1F+ldw0IP/tMgRIuhB23CtW7t36KfMkXDFUNZulTjdVNF6EFFxIpRLIu+rKxSQywsgwbp\nNahqzvxk0727Wqfein39+uijYi0i2qyfOVO/J0LoO3RQ19q4ccG47tCIG0u0QVNffaWtuNCOXSuO\nfvzONpbea9Vv3Qr/938aBupngvWaYNs2fa+K0NuIG69FD5Et+pp024A/oW8HeOVobWCZl7nAyMDn\nc4FGIlJhfKKIDATqApUum4hcKyIzRGTGpuokvQgReuu6SZSPHvylQTAm8qhYL/GEWN5+uyb8Co1H\nT4WOWMuQIWoNelMu2BTRkSx6ez5+YsOHDk1Muulk0KOHvnv99LEGS3np3DmY5iIRQg9qjS9bFoyp\njyb04Sz6n34K+tZD/f3ff6+t1kiuSy/hRsf+3//pWJR9+5I3BZ+16KOli4jEwoUaHRY6x0PHjlpp\neiuvmo6hh8R1xt4GDBOR2cAwYB1Qfioi0gb4N3ClMaYsdGdjzHPGmDxjTF6L6gztDEwMbqkpiz6W\n0G/erNZbrM7ReEbHrl6tFsazz1ZcPnu2RkjYEL5kcvDBKhbe5qqIingki94TKJXRJELo7YjsRAn9\neeep62jcOP2+bJkKc7sQMy5Svpv584PlGT++4ohPvxE3EH507PjxWjZbrni45JLE5Hfyum78pj2x\nLFigFWadOhWXd+igIm+vZ2mptv5TQejXAd7YkfaBZeUYY9YbY0YaY/oDdwWWbQcQkVzgA+AuY8y3\nCSl1JCJY9LXturERN7Esejs6NtZNVFQUfAgee6xiB9Xs2RpBEZr1MZWwE7WHwy6vzmjPdKB5c315\nO2St68YPXtFMlNAfdBCceSZMmKDW89Kl2iILTcLXpo1a76GphOfN0/c771Qx9E7kXh2hz8/XMRPW\nTRdP1Mv69drv8MQTwYymVcW6bnbt0vOPh4ULK/vnoXIs/dq1el1TwXUzHegiIoeISF3gIuBd7wYi\n0lxE7LHuAF4ILK8LvIV21L6euGJHoBZ89H5cN5Hy0IfSoYNaabGOt26dVgaXXqrN2xdf1OXGJD/1\ngR8aN47surHLM92ih4o5b3bv1ts1HovekiihB3XfbNoEn35aObTS0qZNcBIfL/PmqUhfd522Km3L\nYNcuFW2/Qm/HRFihtx3Et9yi9048Qv/OO/repQtce23VY+BBLXorzPH46Xfu1Moq1D8PlaPtajo9\nsSWm0BtjSoAbgY+AxcBrxpiFIjJWRM4KbHYcsFRElgGtADvF7QXAscAVIjIn8OqX6JMoJ6RXryY7\nY6NZ4bFGxVr8hljaiuPSS3VKsj//WS0wO4Am1YXej0W/Pwh99+5BofcbWmmpKaEfMULv6RdfVF+x\nN+LGEmnQ1Lx52prMzYWzztI5f4uLg+LlV+jr1YMmTbQiMUYrjCFDNNzQJsvzy5tvamU1ebK6RS69\ntGqducbos2WnX4xH6O1/HE7oQ8fP1HR6YosvH70xZpIxpqsxprMx5oHAsnuMMe8GPr9ujOkS2OZq\nY8y+wPJxxpg6xph+ntecGjmT4mL1aXgU44wz4IYbEt8ZW1wcPXXB6tU6SKZJk+jH8jtoyq7v2FGb\nyatWqdWTSh2x0cjNjW3RZ7rrBtSi37JFLWgbxeLXdXPwwcGO6EQKfd26cMEFOjF1WVlkix4qCn1J\nibon+vTR76NH67l99FF8oZUWOzp2zhwVytGjdXk8E89v3aoT7owcqb/99NPqAnroodj7hrJnj7pM\n7fiUeIR+wQJ9Dyf0jRvr82CNtx9+0P810sDKRJE5I2M9KYoteXnw978nNu7az6ApG1oZ63f9zjRl\nhb5DB83B3qeP3rwzZwZnr0llXGesYjtklyyJ36KvU0cr+qysxMdbX3JJsIUaTei9IZbLl2tEjBX6\nU09VI2jcuPgtegiOjh03Ts/VTinZrZve/35yQr3/vlrv556r30ePhp/9DO67r/LcwrGwHbGtWulz\nF4/QL1qkrZRI5+8Nwli5Ur/XdB9b5gh9To7OWTdoUI3+jJ80CKtWxe6IBb2J6tTx57pp1kwHzYio\nVb90qVos3bvr8lTGdcYq3sibeIUeVDiqk4s+EkcfHRyVGc5106qV/qbXorcdsVbo69aFCy9UH7lN\nyRHPvACtWwc7Uk8/PbivLU9o5s9wvPmmpkS27hYRfUY6dNDKLFqq7FC8M3mFTtAeCxsuGSkU2BtW\nXRsx9JBJQp+bC2PH1rjQ+8lJH2tUrCUrS29MPxa9t2k3apR2Nm3blvpuG4jdGStS9RmT0okOHbRS\ntkJfp058s2ENH14zs4VlZWnH57HHhq9w69TRkZteoZ8/X4XMVl6gFvTeveqrj8eaBxX6H35Qq966\nbcD/xPO7dqnb6NxzK1aEjRvDU0/psf/7X//lsRE3TZrEL/T5+dHTGXjnoqjp9MSWzBH6WiKW62bX\nLo2j92PRg78JSNasqXi87GwYE8g4lA5Cn5ur/s5wE2/YoQ+hIX2ZSFaWCtfixcEpBOOxzm+9Fd54\no2bKdvPN0YUwdHTsvHnamrSx7qBZMQ89NPY8seGwg6YaN1aL3tKli77HEvoPP9RKZuTIyuusrzye\nEMlQi/6nn/y3CGIJfYcO2k+zdat2QDuLPgWJ5brxG1pp8TNoavXqyp01l14KDz6o76lOtFTFsVIU\nZxo2xDKewVKpQOigqXnzgm4bi0jQGq+KRQ/qm7cpkkFbQB06xI68efNNHacQLuGdHYNZHaEHfyNk\nd+5UbYj2/Fujzc6a5iz6FCSWRR+v0HfsqIMmIoWAFRZWjOe11KkDd9yRHnnZo6UqjpWiONPo0UPv\nkRUr/EfcpALeNAg7dmg/VKjQgwq9na4wHrp104riiivCr4tm0RcVaUfsWWeF79Rs2FBdg/EIfajr\nBvy5b2xodSyLHoItKCf0KUj9+nrjRBJ6v6NiLXZIdKR83N7QynQlWmIzPymKMwnr087PTy+Lvk0b\nvUdLS4OpD8IJfZcuWpGNGhXf8QcP1oGBxxxTeZ0V+khjVz7/XO+jcG4bS8uW6i7xi7XoGzeOT+jz\n8/U9HqF3rpsUpVmz6K6b7Gz/1lqsEEtvaGW6Ei1VsZ8UxZmEt/MynYS+bVuNs9+0qXLETSitW1et\nzyXS9ejaVYU8kkX+5psacnriiZGP3aJF/K6bhg01mqhxY33mEyX0drL0OXP0N6qT3ssvTuirQLTE\nZqtWaVIov3GxsUbHZoLQx7Lo9yehP+ywYNhdurluQN038+apSyM0+VlNES3yprRUQzpPP72ibz+U\neC36bdsqDkw79FD/Ql+/frBzORz162t5ysrUbVMb8ys4oa8C0RKbxcpDH0qs0bGrV6t1lE6iEIrr\njA1St27QFZBOFr130JTtiK2tCWCiCf3XX6ulbgdJRaIqFr13ZLvfEMv8/PgGS9aG2wac0FeJaInN\n/MbQWxo3Vsth+fLw69es0YcsNN1pOuE6Yyti3TfpJPTW0Fi/Xn30kdw2NUGHDhrGGS7y5rXX1EI+\n7bTox2jZUoXeb7rh0CkbO3fWZ7u4OPp+sUIrLbYlXxsdseCEvkpEct2UlGgETTwdpyIaoWDz1oQS\nGkOfjkSy6IuLNYvj/mTRQ3oKvQ1//PprDSGsTaHPztZO3lCLvrhYB2eddVbsfFYtW+r20eYu9hLq\nuuncOZg7Php+hd5Zox3KpgAAG1xJREFU9GlApAyWGzbozRCPRQ866GnevMr5viF8DH26Ua+evkIf\nsjDpifYLrr5aM5CmQ2ispW5dbcl+9JF+r02hh/Ahlh9/rIMTvSNpIxFvLH041w1Ed9/s3KnlcRZ9\nhtCsmYryzp0Vl8cbWmnp109H9YU2TY2pnP4gXQmX72Z/SmjmpXNn+O1v02+ScxtLLxI+M2NN0rWr\nDljyuk7GjVOj69RTY+9vK1W/HbLhXDcQXej9xNBbevbUvreePf2Vp7o4oa8CkQZN+c1DH4pNYxDq\nvtm8WSuAdHfdQPhUxftTiuJMwPrpO3eu/dxE3bqpcWXztxcWarTNhRdqayMW8Vj0ZWWVhb5NG+0L\niCb0fkIrLcOH67FC55StKZzQVwGbiCo08sbGwscrzDZnSKjQZ0JopSVcquL91aJPV2yfQm27baBy\n5M1bb2nOeD9uGwha9H6EvrBQW9Ne101WVuwQy3gsehF/2yUKJ/RVIJpF36xZ/NZOnTqaUz6Thd5Z\n9OlPMoXepiu27s1x49S/PXiwv/2tRe/HdePNc+MlVoilnxj6ZOGEvgpESmwWbwy9l/79Vei9HbxV\nbSGkIs6iT3+s6yYZQt+0qSYtW7pU+wk++0yteb/9HPXq6X3mx6K3eW7CCf3KlZFDNP3G0CcDJ/RV\nIFxO+sJC+O67ikPc46F/f73BvKkQ1qzRG7Q2hkjXNK4zNv3Jy1N3xlFHJef3beTNxInqR7/kkvj2\n9zs61lr0oVOBdu6s4cCR8lL5Da1MBk7oq4C9AbxC/49/qFDffHPVjhmuQ9ZG3KSihRAvznWT/gwe\nrPd8suL/7UTh48ZppRNu2sNo+B0dG811A5HdN07oM4x69dQPb103e/fCY4/BSSfBwIFVO2afPtrh\n4xX6TIiht1jXjbfZW1Cgg2EaNEheuRzpQ7duak3PmuW/E9aLHR0bi2iuGwgv9Lt2aWvBCX2G4U2D\n8OKLegPeeWfVj9ewod7I4Sz6TCA3VweT7d4dXGbz3GRCi8VR81gLPjsbLroo/v2r67rp1EmNsXBC\nX9XQ6trCCX0VsWkQiovhT39Sv2V15/O0HbKgMcPr12dGRyyEz3ezP+a5cVQdG3lz8slVi2xp0UKF\nvqws+nbbt6vxEXpv1q2rhlc4oY8nhj4Z+BJ6ERkuIktFZIWIjAmz/mAR+UxE5onIlyLS3rPuchFZ\nHnhdnsjCJxObk37CBK3N77qr+pZp//6aK2fz5mA6hUyy6MEJvaPqdOmi7tHbbqva/i1b6jNlLfZI\nbNum92W4nPp9+8L//lc58ibthV5EsoGngBFAT+BiEQkduPso8Ioxpg8wFngosG9T4F5gEDAQuFdE\nQhpE6UnTpirIDz2k/nXvhMZVxdshm0kx9BB+8pH9LUWxo3rUqQOffBJ9gpFo+B0dG5rnxsvZZ6th\nFzrmJT9f++5SMYYe/Fn0A4EVxpiVxpgiYCJwdsg2PYHPA5+/8Kw/FfjEGLPVGLMN+AQYXv1iJ5+m\nTTUCYMkS9c0nws/sFfpMiqEHZ9E7ko/f0bGh6Q+8nHWWWvpvvllxuY2hr8rMWrWBn2K1A7zTYqwN\nLPMyF7AzNp4LNBKRZj73RUSuFZEZIjJjUzzTwCQRG0t/2GHxz48ZiaZNVdgz0aIPl6rYWfSO2sRv\nYrNoQt+8OQwbpikYvKxalbpuG0hcZ+xtwDARmQ0MA9YBpX53NsY8Z4zJM8bktUiT0UF2dOyYMcGp\n4RKB7ZBds0ZFMFMsXtcZ60g2fl03obnoQzn3XFi0SFvzllSOoQd/Qr8O8NqV7QPLyjHGrDfGjDTG\n9AfuCizb7mffdOXMM+FXv4JLL03scfv3V5fQ4sWZY82Dc904kk/z5vpeHR89wDnn6Lu16nfv1mOm\nu9BPB7qIyCEiUhe4CHjXu4GINBcRe6w7gBcCnz8CThGRJoFO2FMCy9Kerl3hiSf8pUiNh/79tUf/\nv//NTKG3rpt9+/TlXDeO2qJOHRXw6rhuQJ/LgQODQh9P1spkEVPojTElwI2oQC8GXjPGLBSRsSJy\nVmCz44ClIrIMaAU8ENh3K/AHtLKYDowNLHNEwHbIFhdnTkcsQE6ODgqzFr3Lc+NIBrFGxxYX64RC\n0YQe1H0zfboGTaR6aCVAjp+NjDGTgEkhy+7xfH4deD3Cvi8QtPAdMWjfPhijn0kWPVTMd+Py3DiS\nQazRsfa+jOa6ARg5Eu64A95+W1sKkNpCn6LBQPsvIkGrPtOE3puq2Fn0jmQQK7FZpIRmoXTtqtMp\nvvlm6sfQgxP6lMQKfSa5bqBiqmIn9I5kEMt1EymhWTjOPRemTlUXTirH0IMT+pTkhBN0ppru3ZNd\nksTSuLFz3TiSS4sW6hYtjRD8HSmhWThGjtS8OV98kdpuG3BCn5IMH643Y+vWyS5JYnEWvSPZtGyp\nUW2hs8NZ/LpuAPr1Cwq8E3pHlWjYMNklSDyuM9aRbGKNjo3HdSOi7htIfaH3FXWTbIqLi1m7di17\n9+5NdlEc1eDqqzWP+OLFOkPQ5Mn6wG3eXLXj1a9fn/bt21PHhj04HDHwjo49/PDK6+Nx3YCmP3n8\ncc2smcqkhdCvXbuWRo0a0alTJ8TNUpG2rFun6Ze7d9fPdepAz9A8qD4xxrBlyxbWrl3LIYccktiC\nOjKWWInNtm8Pjvnww9FHa9riqs4sV1ukhetm7969NGvWzIl8mmNzApWVaWdYdXIEiQjNmjVzrTxH\nXFiLPprr5qCD4stGe/TRWjmkMmkh9IAT+QzACntpafWFHtw94YifZs1UxKNZ9H7dNulE2gi9I/1J\ntNA7HPGSna3JzSJZ9LHy3KQrTuh9sGXLFvr160e/fv1o3bo17dq1K/9eVFTk6xhXXnklS5cujbrN\nU089xfjx4xNR5JTECb0jFYg2OjZWiuJ0JcU9S6lBs2bNmDNnDgD33XcfBx54ILeFTFxpjMEYQ1aE\n4XEvvvhizN+54YYbql/YWqakpIQcnw7KUKGvV68GC+ZwRCDa6Njt23WUa6aRfhb9r38Nxx2X2Nev\nf12loqxYsYKePXtyySWXcPjhh7NhwwauvfZa8vLyOPzwwxk7dmz5tkOGDGHOnDmUlJRw0EEHMWbM\nGPr27cvgwYP5KXDX3X333TzxxBPl248ZM4aBAwfSrVs3vv76awB27drFeeedR8+ePRk1ahR5eXnl\nlZCXe++9lyOPPJJevXrxi1/8AhOYzXjZsmWccMIJ9O3blwEDBpAfSL334IMP0rt3b/r27ctdd91V\nocwAP/74I4cddhgAzz//POeccw7HH388p556KgUFBZxwwgkMGDCAPn368P7775eX48UXX6RPnz70\n7duX66+/kp07d9C376Hs21dCdjZs27aNQw89lJKSkir9Bw5HvLRo4Vw3jjhZsmQJt9xyC4sWLaJd\nu3Y8/PDDzJgxg7lz5/LJJ5+waNGiSvvs2LGDYcOGMXfuXAYPHswLL4RP7mmMYdq0aTzyyCPllcbf\n/vY3WrduzaJFi/j973/P7NBZigP86le/Yvr06cyfP58dO3bw4YcfAnDxxRdzyy23MHfuXL7++mta\ntmzJe++9x+TJk5k2bRpz587l1ltvjXnes2fP5s033+Szzz6jQYMGvP3228yaNYtPP/2UW265BYC5\nc+fypz/9iS+//JK5c+fyyCOPceCBjTnyyGP46qsPyc6GCRMmcP755/tuFTgc1SWSRW+Mc92kDgGL\nN1Xo3LkzeXl55d8nTJjAv/71L0pKSli/fj2LFi2iZ0iweIMGDRgxYgQARxxxBFOnTg177JEjR5Zv\nYy3vr776it/97ncA9O3bl8PDjfoAPvvsMx555BH27t3L5s2bOeKIIzjqqKPYvHkzZ555JqADjgA+\n/fRTrrrqKho0aABAUztPYhROOeUUmgTCE4wxjBkzhq+++oqsrCzWrFnD5s2b+fzzz7nwwgvLj9e8\neVPWroWLL76av//9r5x33hm8+OKL/Pvf/475ew5HomjZUgW9uDiYYhhg714oKsrMqJv0E/oU44AD\nDij/vHz5cp588kmmTZvGQQcdxOjRo8PGedf1TEuVnZ0d0W1RL+DEjrZNOHbv3s2NN97IrFmzaNeu\nHXfffXeV4s1zcnIoKysDqLS/97xfeeUVduzYwaxZs8jJyaF9+/Zhf8/66I88chirV9/IN998QZ06\ndeieadnbHCmNjaXfvBnatAkujyfPTbrhXDcJpKCggEaNGpGbm8uGDRv46KPEz5p4zDHH8NprrwEw\nf/78sK6hPXv2kJWVRfPmzSksLOSNN94AoEmTJrRo0YL33nsPUPHevXs3J598Mi+88AJ79uwBYOtW\nnQSsU6dOzJw5E4DXXw87rwygrqiWLVuSk5PDJ598wrp1Oi3wCSecwKuvvlp+vG3btpKVpVbTiBGj\nufHGS7jyyisTcVkcDt9EGh0bT56bdMMJfQIZMGAAPXv2pHv37lx22WUcc8wxCf+Nm266iXXr1tGz\nZ0/uv/9+evbsSeOQzGDNmjXj8ssvp2fPnowYMYJBgwaVrxs/fjyPPfYYffr0YciQIWzatIkzzjiD\n4cOHk5eXR79+/Xj88ccB+O1vf8uTTz7JgAED2GafgjBceumlfP311/Tu3ZuJEyfSJZD4o2/fvtx+\n++0ce+yx9OvXj9/+9rfk5GiTefjwSygs3MGFF16Y8GvkcEQj0ujYTLboxUZjpAp5eXlmxowZFZYt\nXryYHj16JKlEqUVJSQklJSXUr1+f5cuXc8opp7B8+fK06cxcsEBTILz//kQWLvyI8eNjh51Gw90b\njnhZsgR69IDx4+FnPwsunzQJTj8dvv0WPLZR2iAiM40xeeHWpYc6OMrZuXMnJ554IiUlJRhj+Mc/\n/pE2Ig/qp7/vvuuZNu1T3nvvw2QXx7EfEilVcSa7btJHIRwAHHTQQeV+83QkOxvGjHkGSP3Uro7M\n5KCD9D4M9dFnsuvG+egdtYo37YFLgeBIBllZ4dMgOKF3OBKEE3pHKhBudOy2bdCgQWam5vAl9CIy\nXESWisgKERkTZn1HEflCRGaLyDwROS2wvI6IvCwi80VksYjckegTcKQXXnGPkBbI4ahxwo2OzdT0\nB+BD6EUkG3gKGAH0BC4WkdB5ge4GXjPG9AcuAp4OLD8fqGeM6Q0cAVwnIp0SU3RHOmKFPivLCb0j\nebRsCT/8ADt3Bpdlai568GfRDwRWGGNWGmOKgInA2SHbGCA38LkxsN6z/AARyQEaAEVAQbVLXcsc\nf/zxlQY/PfHEE1x//fVR9zvwwAMBWL9+PaNGjQq7zXHHHUdoOGkoTzzxBLt37y7/ftppp7HdOhTT\nDCv0zm3jSCaXXaaum7PP1tQHkLl5bsCf0LcD1ni+rw0s83IfMFpE1gKTgJsCy18HdgEbgNXAo8aY\nraE/ICLXisgMEZmxKVJauSRy8cUXM3HixArLJk6cyMUXX+xr/7Zt20YdWRqLUKGfNGkSB6XRHWmM\nKU+l4ITekQoMHw4vvQRffKETfBcV7eeuG59cDLxkjGkPnAb8W0Sy0NZAKdAWOAS4VUQODd3ZGPOc\nMSbPGJPXwg5bi0AyshSPGjWKDz74oHySkfz8fNavX8/QoUPL49oHDBhA7969eeeddyrtn5+fT69e\nvQBNT3DRRRfRo0cPzj333PK0AwDXX399eYrje++9F4C//vWvrF+/nuOPP57jjz8e0NQEmzdvBuAv\nf/kLvXr1olevXuUpjvPz8+nRowfXXHMNhx9+OKecckqF37G89957DBo0iP79+3PSSSexceNGQGP1\nr7zySnr37k2fPn3KUyh8+OGHDBgwgL59+3LiiScCmp//0UcfLT9mr169yM/PJz8/n27dunHZZZfR\nq1cv1qxZw/XXX8/JJ+dxwQWH8/TT95bvM336dI4++mj69u3LwIEDKSws5Nhjj62QfnnIkCHMnTs3\n+h/lcMTB6NHw7LPwwQdwySWwZUvmum78xNGvAzp4vrcPLPPyc2A4gDHmGxGpDzQHfgZ8aIwpBn4S\nkf8BecDK6ha8NmnatCkDBw5k8uTJnH322UycOJELLrgAEaF+/fq89dZb5ObmsnnzZo466ijOOuus\niPOZPvPMMzRs2JDFixczb948BgwYUL7ugQceoGnTppSWlnLiiScyb948br75Zv7yl7/wxRdf0Lx5\n8wrHmjlzJi+++CLfffcdxhgGDRrEsGHDaNKkCcuXL2fChAn885//5IILLuCNN95g9OjRFfYfMmQI\n3377LSLC888/z5///Gcee+wx/vCHP9C4cWPmz58PaM74TZs2cc011zBlyhQOOeSQ8vw10Vi+fDkv\nv/wyRx11VPn55eQ0ZfHiUm66Sc+ve/fuXHjhhbz66qsceeSRFBQU0KBBA37+85/z0ksv8cQTT7Bs\n2TL27t1L37594/rfHI5YXHst7NoFv/mNfj/jjOSWp6bwI/TTgS4icggq8BehAu5lNXAi8JKI9ADq\nA5sCy09ALfwDgKOAauUZTlaWYuu+sUL/r3/9C1C3xJ133smUKVPIyspi3bp1bNy4kdatW4c9zpQp\nU7j55psB+P/27j+mqvOO4/j7uxbL/K2rMUQaZVsVf3FBiti0EHVhYXXRiCNOSSixzMRU7JomS43W\nuBn/WDTbmmhWyWYryXSybuKP6NqOkar/WJECIuraBU2pt+qQKkIyx/bdH+dwc6HCRS2cc0++r+SE\ne557gc9DHr733Oee+5y0tDTS0tIi91VWVlJeXk53dzfhcJjm5uZe9/d1+vRpli9fHllJsqCggFOn\nTrF06VJSUlJIT08Hei9zHK21tZWVK1cSDoe5d+8eKSkpgLNscfRU1YQJEzh69Ci5ubmRxwxmKeOp\nU6dGinxP/956q5zOzm7a2pz+iQhJSUlkZWUBMHas81ZPYWEh27ZtY8eOHezdu5eSkpKYv8+Yh/Hq\nq06xf+MN5+LhQRRz6kZVu4H1wHvARZyzay6IyC9EZKn7sNeAn4hIA3AAKFFnEZ3dwGgRuYDzhPG2\nqjYORUeG2rJly6iurqauro6uri4yMzMBZ5Gwmzdvcu7cOerr65k8efJDLQnc0tLCzp07qa6uprGx\nkSVLljzUz+nxRNTJwP0tc1xWVsb69es5f/48e/bseeSljKH3csbRSxn39O/48WoOHGhk8eKB+zdy\n5Ejy8vI4fPgwlZWVFBUVPXA2YwZr0yaoqoIY51fErUHN0avqcVWdrqrfUdXtbtsWVT3i3m5W1edU\nNaSq6ar6vtt+V1ULVXW2qs5S1R1D15WhNXr0aBYtWsSaNWt6vQnbs0RvQkICNTU1XL16dcCfk5ub\ny/79+wFoamqisdF53rtz5w6jRo1i3LhxXL9+nRMnTkS+Z8yYMXR0dHzlZ+Xk5FBVVUVXVxednZ0c\nOnSInJycQffp9u3bTJnivK++b9++SHteXh67d++O7Le3t7NgwQJOnjxJS0sL0Hsp47q6OgDq6uoi\n9/fV07+JE8fR1nadDz90+jdjxgzC4TBnz54FoKOjI/KkVFpayoYNG8jKyopc5MSYoSDinIHTzwvx\nuGdnMj+AVatW0dDQ0KvQFxUVUVtby9y5c6moqIh5EY1169Zx9+5dZs6cyZYtWyKvDEKhEBkZGaSm\nprJ69epeSxyvXbuW/Pz8yJuxPebNm0dJSQnz588nOzub0tJSMjIyBt2frVu3UlhYSGZmZq/5/82b\nN9Pe3s6cOXMIhULU1NQwadIkysvLKSgoIBQKRZYXXrFiBbdu3WL27Nns2rWL6dOn3/d39fQvLS2V\nzZtX88wzTv9GjBjBwYMHKSsrIxQKkZeXFznSz8zMZOzYsbZmvTGPyJYpNsMuHHZOY3OvXNiva9eu\nsXDhQi5dusQ3+vl0lY0NYxwDLVNsR/Rm2CUlxS7yFRUVZGdns3379n6LvDFmcGyZYuNLxcXFFBcX\nex3DmECIm0Mlv00xGe/ZmDBmcOKi0CcmJtLW1mb/2CZCVWlrayMxMdHrKMb4XlxM3SQnJ9Pa2oof\n18Ex3klMTCQ5OdnrGMb4XlwU+oSEhMgnMo0xxjyYuJi6McYY8/Cs0BtjTMBZoTfGmIDz3SdjReQm\nMPCCMQN7EvjX1xRnOFnu4WW5h5flHnpTVfW+F/TwXaF/VCJS29/HgP3Mcg8vyz28LLe3bOrGGGMC\nzgq9McYEXBALfbnXAR6S5R5elnt4WW4PBW6O3hhjTG9BPKI3xhgTxQq9McYEXGAKvYjki8hlEflU\nRF73Os9ARGSviNwQkaaotoki8oGIfOJ+9dVFUkXkKRGpEZFmEbkgIq+47X7PnSgiH4lIg5v75257\nioicccfLQREZ4XXW+xGRx0TkYxE55u7HS+4rInJeROpFpNZt8/VYARCR8SLyrohcEpGLIvJsPOSO\nJRCFXkQeA3YDPwBmAatEZJa3qQb0DpDfp+11oFpVnwaq3X0/6QZeU9VZwALgZfdv7Pfc/wYWq2oI\nSAfyRWQB8Evg16r6XaAdeMnDjAN5BbgYtR8vuQEWqWp61Hnofh8rAG8Cf1XVVCCE87ePh9wDU9W4\n34Bngfei9jcCG73OFSPzNKApav8ykOTeTgIue50xRv7DQF485QZGAnVANs6nHR+/3/jxywYk4xSW\nxcAxQOIht5vtCvBknzZfjxVgHNCCe5JKvOQezBaII3pgCvBZ1H6r2xZPJqtq2L39BTDZyzADEZFp\nQAZwhjjI7U5/1AM3gA+AfwJfqmq3+xC/jpffAD8D/ufuf4v4yA2gwPsick5E1rptfh8rKcBN4G13\nuux3IjIK/+eOKSiFPlDUOXTw5XmvIjIa+DPwU1W9E32fX3Or6n9VNR3nCHk+kOpxpJhE5IfADVU9\n53WWh/S8qs7DmU59WURyo+/06Vh5HJgH/FZVM4BO+kzT+DR3TEEp9J8DT0XtJ7tt8eS6iCQBuF9v\neJznK0QkAafI/0FV/+I2+z53D1X9EqjBmfIYLyI9F97x43h5DlgqIleAP+JM37yJ/3MDoKqfu19v\nAIdwnmD9PlZagVZVPePuv4tT+P2eO6agFPqzwNPuGQkjgB8DRzzO9KCOAC+6t1/EmQP3DRER4PfA\nRVX9VdRdfs89SUTGu7e/ifO+wkWcgv8j92G+y62qG1U1WVWn4Yznv6tqET7PDSAio0RkTM9t4PtA\nEz4fK6r6BfCZiMxwm74HNOPz3IPi9ZsEX9cGvAD8A2f+dZPXeWJkPQCEgf/gHEW8hDP/Wg18AvwN\nmOh1zj6Zn8d5ydoI1LvbC3GQOw342M3dBGxx278NfAR8CvwJeMLrrAP0YSFwLF5yuxkb3O1Cz/+j\n38eKmzEdqHXHSxUwIR5yx9psCQRjjAm4oEzdGGOM6YcVemOMCTgr9MYYE3BW6I0xJuCs0BtjTMBZ\noTfGmICzQm+MMQH3f6yOavMB1g47AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koDPVvf6GXVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}